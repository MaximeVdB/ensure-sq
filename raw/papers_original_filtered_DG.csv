Authors,Title,Year,Source title,Link,Abstract
"Karhapää P., Behutiye W., Rodríguez P., Oivo M., Costal D., Franch X., Aaramaa S., Choraś M., Partanen J., Abherve A.",Strategies to manage quality requirements in agile software development: a multiple case study,2021,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102137144&doi=10.1007%2fs10664-020-09903-x&partnerID=40&md5=6cb7f0defb9e1b5c8f2f6aa170526fa0,"Agile methods can deliver software that fulfills customer needs rapidly and continuously. Quality requirements (QRs) are important in this regard; however, detailed studies on how companies applying agile methods to manage QRs are limited, as are studies on the rationale for choosing specific QR management practices and related challenges. The aim of this study was to address why practitioners manage QRs as they do and what challenges they face. We also analyzed how existing practices mitigate some of the found challenges. Lastly, we connect the contextual elements of the companies with their practices and challenges. We conducted 36 interviews with practitioners from four companies of varying sizes. Since each company operates in different domains, comparing QR management strategies and related challenges in different contexts was possible. We found that the companies apply proactive, reactive, and interactive strategies to manage QRs. Additionally, our study revealed 40 challenges in six categories that companies applying agile methods may face in QR management. We also identified nine contextual elements that affect QR management practice choices and which, importantly, can explain many related challenges. Based on these findings, we constructed a theoretical model about the connection between context, QR management practices, and challenges. Practitioners in similar contexts can learn from the practices identified in this study. Our preliminary theoretical model can help other practitioners identify what challenges they can expect to face in QR management in different developmental contexts as well as which practices to apply to mitigate these challenges. © 2021, The Author(s)."
"Pecorelli F., Palomba F., De Lucia A.",The Relation of Test-Related Factors to Software Quality: A Case Study on Apache Systems,2021,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101418276&doi=10.1007%2fs10664-020-09891-y&partnerID=40&md5=d7bb069057ccf0279332887fd7b9e31a,"Testing represents a crucial activity to ensure software quality. Recent studies have shown that test-related factors (e.g., code coverage) can be reliable predictors of software code quality, as measured by post-release defects. While these studies provided initial compelling evidence on the relation between tests and post-release defects, they considered different test-related factors separately: as a consequence, there is still a lack of knowledge of whether these factors are still good predictors when considering all together. In this paper, we propose a comprehensive case study on how test-related factors relate to production code quality in Apache systems. We first investigated how the presence of tests relates to post-release defects; then, we analyzed the role played by the test-related factors previously shown as significantly related to post-release defects. The key findings of the study show that, when controlling for other metrics (e.g., size of the production class), test-related factors have a limited connection to post-release defects. © 2021, The Author(s)."
"Trautsch A., Herbold S., Grabowski J.",A longitudinal study of static analysis warning evolution and the effects of PMD on software quality in Apache open source projects,2020,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091245352&doi=10.1007%2fs10664-020-09880-1&partnerID=40&md5=077dac4a9230c050eb6b28ff2c596d4c,"Automated static analysis tools (ASATs) have become a major part of the software development workflow. Acting on the generated warnings, i.e., changing the code indicated in the warning, should be part of, at latest, the code review phase. Despite this being a best practice in software development, there is still a lack of empirical research regarding the usage of ASATs in the wild. In this work, we want to study ASAT warning trends in software via the example of PMD as an ASAT and its usage in open source projects. We analyzed the commit history of 54 projects (with 112,266 commits in total), taking into account 193 PMD rules and 61 PMD releases. We investigate trends of ASAT warnings over up to 17 years for the selected study subjects regarding changes of warning types, short and long term impact of ASAT use, and changes in warning severities. We found that large global changes in ASAT warnings are mostly due to coding style changes regarding braces and naming conventions. We also found that, surprisingly, the influence of the presence of PMD in the build process of the project on warning removal trends for the number of warnings per lines of code is small and not statistically significant. Regardless, if we consider defect density as a proxy for external quality, we see a positive effect if PMD is present in the build configuration of our study subjects. © 2020, The Author(s)."
Alami A.,The sustainability of quality in free and open source software,2020,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094174322&doi=10.1145%2f3377812.3381402&partnerID=40&md5=afb03b21ee1d83333f142cfdf9d75b14,"We learned from the history of software that great software are theones who manage to sustain their quality. Free and open sourcesoftware (FOSS) has become a serious software supply channel.However, trust on FOSS products is still an issue. Quality is a traitthat enhances trust. In my study, I investigate the following question: how do FOSS communities sustain their software quality? Iargue that human and social factors contribute to the sustainabilityof quality in FOSS communities. Amongst these factors are: themotivation of participants, robust governance style for the software change process, and the exercise of good practices in the pullrequests evaluation process. © 2020 Copyright held by the owner/author(s)."
"Kavalchuk A., Goldenberg A., Hussain I.",An empirical study of teaching qualities of popular computer science and software engineering instructors using RateMyProfessor.com data,2020,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093651824&doi=10.1145%2f3377814.3381700&partnerID=40&md5=548f17e80886b8cef5906827f72cb85a,"The employment opportunity for Computer Science (CS), Information Technology and Software Engineering and Development (SE) related occupations is projected to grow much faster than the average of all other occupations. Therefore, increase in student enrollment, retention and graduation rate is becoming very important, so is the need for effective teaching in these subjects. Many universities commonly use formal, institutional Student Evaluation of Teaching (SET) systems to measure the teaching effectiveness. After each semester, through SET, students provide feedback and comments for their courses and instructors. However, evaluations are private and only a handful people have access to these. Therefore, these evaluations cannot be utilized to create a common understanding of the students' expectations, perspective, desired characteristics of the courses and instructors. On the other hand, third party online platforms like RateMyProfessor.com (RMP) are public, solicit anonymous student feedback and host tremendous amount of data about the instructors and their courses. These platforms are also popular among students. We mined and analyzed the RMP data for some research questions, e.g.: What are the common characteristics of the popular CS instructors? How different are they for the SE instructors? Are there any examples of special characteristics, tools and techniques popular CS instructors use? We captured and analyzed more than 9,000 students' comments for over 300 CS instructors for the top 20 universities in the U.S. and Canada. The paper contributes by presenting the findings for the research questions and making the data and the scripts available for public use for future research. © 2020 IEEE Computer Society. All rights reserved."
"Dey T., Mockus A.",Deriving a usage-independent software quality metric,2020,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079758011&doi=10.1007%2fs10664-019-09791-w&partnerID=40&md5=6305e781914a82218ae0b82161c1ec56,"Context: The extent of post-release use of software affects the number of faults, thus biasing quality metrics and adversely affecting associated decisions. The proprietary nature of usage data limited deeper exploration of this subject in the past. Objective: To determine how software faults and software use are related and how, based on that, an accurate quality measure can be designed. Method: Via Google Analytics we measure new users, usage intensity, usage frequency, exceptions, and release date and duration for complex proprietary mobile applications for Android and iOS. We utilize Bayesian Network and Random Forest models to explain the interrelationships and to derive the usage independent release quality measure. To increase external validity, we also investigate the interrelationship among various code complexity measures, usage (downloads), and number of issues for 520 NPM packages. We derived a usage-independent quality measure from these analyses, and applied it on 4430 popular NPM packages to construct timelines for comparing the perceived quality (number of issues) and our derived measure of quality during the lifetime of these packages. Results: We found the number of new users to be the primary factor determining the number of exceptions, and found no direct link between the intensity and frequency of software usage and software faults. Crashes increased with the power of 1.02-1.04 of new user for the Android app and power of 1.6 for the iOS app. Release quality expressed as crashes per user was independent of other usage-related predictors, thus serving as a usage independent measure of software quality. Usage also affected quality in NPM, where downloads were strongly associated with numbers of issues, even after taking the other code complexity measures into consideration. Unlike in mobile case where exceptions per user decrease over time, for 45.8% of the NPM packages the number of issues per download increase. Conclusions: We expect our result and our proposed quality measure will help gauge release quality of a software more accurately and inspire further research in this area. © 2020, Springer Science+Business Media, LLC, part of Springer Nature."
"Brindescu C., Ahmed I., Jensen C., Sarma A.",An empirical investigation into merge conflicts and their effect on software quality,2020,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072196973&doi=10.1007%2fs10664-019-09735-4&partnerID=40&md5=1f8c97f2452902a4690b4cd97cb910a9,"Merge conflicts are known to cause extra effort for developers, but little is known about their effect on software. While some research has been done, many questions remain. To better understand merge conflicts and their impact we performed an empirical study about the types, frequency, and impact of merge conflicts, where impact is measured in terms of bug fixing commits associated with conflicts. We analyzed 143 open source projects and found that almost 1 in 5 merges cause conflicts. In 75.23% of these cases, a developer needed to reflect on the program logic to resolve it. We also found that the code associated with a merge conflict is twice as likely to have a bug. When the code associated with merge conflicts require manual intervention, the code is 26× more likely to have a bug. © 2019, Springer Science+Business Media, LLC, part of Springer Nature."
Datta S.,How does developer interaction relate to software quality? an examination of product development data,2018,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026823677&doi=10.1007%2fs10664-017-9534-0&partnerID=40&md5=1bcbb3493632b82239aeb55703852b5f,"Industrial software systems are being increasingly developed by large and distributed teams. Tools like collaborative development environments (CDE) are used to facilitate interaction between members of such teams, with the expectation that social factors around the interaction would facilitate team functioning. In this paper, we first identify typically social characteristics of interaction in a software development team: reachability, connection, association, and clustering. We then examine how these factors relate to the quality of software produced by a team, in terms of the number of defects, through an empirical study of 70+ teams, involving 900+ developers in total, spread across 30+ locations and 19 time-zones, working on 40,000+ units of work in the multi-version development of a major industrial product, spreading across more than five years. After controlling for known factors affecting large scale distributed development such as dependency, system age, developer expertise and experience, geographic dispersion, socio-technical congruence, and the number of files changed, we find statistically significant effects of connection and clustering on software quality. Higher levels of intra-team connection are found to relate to higher defect count, whereas more clustering relates to fewer defects. We examine the implications of these results for individual developers, project managers, and organizations. © 2017, Springer Science+Business Media, LLC."
"Stevenson J., Wood M.",Recognising object-oriented software design quality: a practitioner-based questionnaire survey,2018,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017566671&doi=10.1007%2fs11219-017-9364-8&partnerID=40&md5=64be91384347ff392179346f104c31a8,"Design quality is vital if software is to be maintainable. What practices do developers actually use to achieve design quality in their day-to-day work and which of these do they find most useful? To discover the extent to which practitioners concern themselves with object-oriented design quality and the approaches used when determining quality in practice, a questionnaire survey of 102 software practitioners, approximately half from the UK and the remainder from elsewhere around the world was used. Individual and peer experience are major contributors to design quality. Classic design guidelines, well-known lower level practices, tools and metrics all can also contribute positively to design quality. There is a potential relationship between testing practices and design quality. Inexperience, time pressures, novel problems, novel technology, and imprecise or changing requirements may have a negative impact on quality. Respondents with most experience are more confident in their design decisions, place more value on reviews by team leads and are more likely to rate design quality as very important. For practitioners, these results identify the techniques and tools that other practitioners find effective. For researchers, the results highlight a need for more work investigating the role of experience in the design process and the contribution experience makes to quality. There is also the potential for more in-depth studies of how practitioners are actually using design guidance, including Clean Code. Lastly, the potential relationship between testing practices and design quality merits further investigation. © 2017, The Author(s)."
"Foidl H., Felderer M.",Integrating software quality models into risk-based testing,2018,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994719172&doi=10.1007%2fs11219-016-9345-3&partnerID=40&md5=08aef64094ee176e3efa77d89641d4fa,"Risk-based testing is a frequently used testing approach which utilizes identified risks of a software system to provide decision support in all phases of the testing process. Risk assessment, which is a core activity of every risk-based testing process, is often done in an ad hoc manual way. Software quality assessments, based on quality models, already describe the product-related risks of a whole software product and provide objective and automation-supported assessments. But so far, quality models have not been applied for risk assessment and risk-based testing in a systematic way. This article tries to fill this gap and investigates how the information and data of a quality assessment based on the open quality model QuaMoCo can be integrated into risk-based testing. We first present two generic approaches showing how quality assessments based on quality models can be integrated into risk-based testing and then provide the concrete integration on the basis of the open quality model QuaMoCo. Based on five open source products, a case study is performed. Results of the case study show that a risk-based testing strategy outperforms a lines of code-based testing strategy with regard to the number of defects detected. Moreover, a significant positive relationship between the risk coefficient and the associated number of defects was found. © 2016, The Author(s)."
"Söylemez M., Tarhan A.",Challenges of software process and product quality improvement: catalyzing defect root-cause investigation by process enactment data analysis,2018,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983535140&doi=10.1007%2fs11219-016-9334-6&partnerID=40&md5=84cd45d8183f9bbdab5d4fa837c0120e,"It is claimed by software quality management that the quality of a software product is highly influenced by the quality of the software process followed to develop it. Since measurement of the software process is a challenging task, it is frequently the defects in the software product that are used to measure development quality. By extracting semantic information from defect records, practitioners can investigate and address root causes of software defects to improve development process and product quality. Investigating root causes requires effort for a detailed analysis into the components of the development process that originated the software defects, and is therefore encouraged only at higher maturity levels by most known process improvement models such as Capability Maturity Model Integration (CMMI). This practice, however, postpones the benefits that root-cause analysis would bring in gaining process awareness to improve the software development process and product quality in emergent organizations or organizations residing at lower maturity levels (MLs). In this article, we present a method for and results from applying root-cause analysis for software defects recorded in a software-intensive project of a CMMI ML3 certified institute. The suggested method combines process enactment data collection and analysis with Orthogonal Defect Classification which is a known technique in defect root-cause analysis. Prior to and after implementing the method in the study, defect attributes were analyzed and compared in order to understand any improvements in development performance and product quality. The results of the comparison indicate that the suggested method was efficient in the effort it required and effective in improving development performance and product quality. Defect triggers have become more active in identifying software defects in the earlier phases of software development, and the cost of quality due to software defects has decreased in consequence. © 2016, Springer Science+Business Media New York."
"Srisopha K., Alfayez R.",Software quality through the eyes of the end-user and static analysis tools: A study on Android OSS applications,2018,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051522416&doi=10.1145%2f3194095.3194096&partnerID=40&md5=7a9dc5d4116e134e2a85128cb3328d90,"Source code analysis tools have been the vehicle for measuring and assessing the quality of a software product for decades. However, recently many studies have shown that post-deployment end-user reviews provide a wealth of insight into the quality of a software product and how it should evolve and be maintained. For example, end-user reviews help to identify missing features or inform developers about incorrect or unexpected software behavior. We believe that analyzing end-user reviews and utilizing analysis tools are a crucial step towards understanding the complete picture of the quality of a software product, as well as towards reasoning about the evolution history of it. In this paper, we investigate whether both methods correlate with one another. In other words, we explore if there exists a relationship between user satisfaction and the application's internal quality characteristics. To conduct our research, we analyze a total of 46 actual releases of three Android open source software (OSS) applications on the Google Play Store. For each release, we employ multiple static analysis tools to assess several aspects of the application's software quality. We retrieve and manually analyze the complete reviews after each release of each application from its store page, totaling 1004 reviews. Our initial results suggest that having high or low code quality does not necessary ensure user overall satisfaction. © 2018 Association for Computing Machinery."
"Srinivasan M., Shahri M.P., Kahanda I., Kanewala U.",Quality Assurance of Bioinformatics Software: A Case Study of Testing a Biomedical Text Processing Tool Using Metamorphic Testing,2018,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051246822&doi=10.1145%2f3193977.3193981&partnerID=40&md5=13df9dbdd437caf62d8e1450305f47c6,"Bioinformatics software plays a very important role in making critical decisions within many areas including medicine and health care. However, most of the research is directed towards developing tools, and little time and effort is spent on testing the software to assure its quality. In testing, a test oracle is used to determine whether a test is passed or failed during testing, and unfortunately, for much of bioinformatics software, the exact expected outcomes are not well defined. Thus, the main challenge associated with conducting systematic testing on bioinformatics software is the oracle problem. Metamorphic testing (MT) is a technique used to test programs that face the oracle problem. MT uses metamorphic relations (MRs) to determine whether a test has passed or failed and specifies how the output should change according to a specific change made to the input. In this work, we use MT to test LingPipe, a tool for processing text using computational linguistics, often used in bioinformatics for bio-entity recognition from biomedical literature. First, we identify a set of MRs for testing any bio-entity recognition program. Then we develop a set of test cases that can be used to test LingPipe's bio-entity recognition functionality using these MRs. To evaluate the effectiveness of this testing process, we automatically generate a set of faulty versions of LingPipe. According to our analysis of the experimental results, we observe that our MRs can detect the majority of these faulty versions, which shows the utility of this testing technique for quality assurance of bioinformatics software. © 2018 Association for Computing Machinery."
"Li M., Chen T., Yao X.","A critical review of ""a practical guide to select quality indicators for assessing pareto-based search algorithms in search-based software engineering"": Essay on quality indicator selection for SBSE",2018,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049805170&doi=10.1145%2f3183399.3183405&partnerID=40&md5=cf1c999ddeb3da395195f2ba42440d27,"This paper presents a critical review of the work published at ICSE'2016 on a practical guide of quality indicator selection for assessing multiobjective solution sets in search-based software engineering (SBSE). This review has two goals. First, we aim at explaining why we disagree with the work at ICSE'2016 and why the reasons behind this disagreement are important to the SBSE community. Second, we aim at providing a more clarified guide of quality indicator selection, serving as a new direction on this particular topic for the SBSE community. In particular, we argue that it does matter which quality indicator to select, whatever in the same quality category or across different categories. This claim is based upon the fundamental goal of multiobjective optimisation-supplying the decision-maker a set of solutions which are the most consistent with their preferences. © 2018 Association for Computing Machinery."
"Wu J., Ali S., Yue T., Tian J., Liu C.",Assessing the quality of industrial avionics software: an extensive empirical evaluation,2017,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976479544&doi=10.1007%2fs10664-016-9440-x&partnerID=40&md5=e1761f9abd032dfbd75cb4f93279a681,"A real-time operating system for avionics (RTOS4A) provides an operating environment for avionics application software. Since an RTOS4A has safety-critical applications, demonstrating a satisfactory level of its quality to its stakeholders is very important. By assessing the variation in quality across consecutive releases of an industrial RTOS4A based on test data collected over 17 months, we aim to provide a set of guidelines to 1) improve the test effectiveness and thus the quality of subsequent RTOS4A releases and 2) similarly assess the quality of other systems from test data. We carefully defined a set of research questions, for which we defined a number of variables (based on available test data), including release and measures of test effort, test effectiveness, complexity, test efficiency, test strength, and failure density. With these variables, to assess the quality in terms of number of failures found in tests, we applied a combination of analyses, including trend analysis using two-dimensional graphs, correlation analysis using Spearman’s test, and difference analysis using the Wilcoxon rank test. Key results include the following: 1) The number of failures and failure density decreased in the latest releases and the test coverage was either high or did not decrease with each release; 2) increased test effort was spent on modules of greater complexity and the number of failures was not high in these modules; and 3) the test coverage for modules without failures was not lower than the test coverage for modules with failures uncovered in all the releases. The overall assessment, based on the evidences, suggests that the quality of the latest RTOS4A release has improved. We conclude that the quality of the RTOS4A studied was improved in the latest release. In addition, our industrial partner found our guidelines useful and we believe that these guidelines can be used to assess the quality of other applications in the future. © 2016, Springer Science+Business Media New York."
"Parthasarathy S., Sharma S.",Impact of customization over software quality in ERP projects: an empirical study,2017,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964057687&doi=10.1007%2fs11219-016-9314-x&partnerID=40&md5=bbbd3a489ccce59d7785bbfd59804021,"Enterprise resource planning (ERP) systems are recognized as management information systems that streamline business processes of an enterprise. Delivering ERP software to meet functional needs of an organization with acceptable level of quality is a challenge due to the very nature of development and deployment of this packaged software. Drawing on ISO/IEC 9126’s characterization of software quality and Luo and Strong’s ERP customization framework, this paper analyzes the impact of the ERP system customization on software quality of ERP. A software quality framework for ERP customization has been developed, and three sets of hypotheses have been formulated. A detailed survey was conducted for data collection. The statistical data analysis reveals that module customization does not impact ERP quality, while database and source code customizations have significant influence over ERP quality. Our findings have implications for the implementation of customized ERP in organizations. © 2016, Springer Science+Business Media New York."
C. Duarte C.H.,Productivity paradoxes revisited: Assessing the relationship between quality maturity levels and labor productivity in brazilian software companies,2017,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989910841&doi=10.1007%2fs10664-016-9453-5&partnerID=40&md5=c4582eabccfbbf9c77fc764b7dd8fa00,"The adoption of quality assurance methods based on software process improvement models has been regarded as an important source of variability in software productivity. Some companies perceive that their implementation has prohibitive costs, whereas some authors identify in their use a way to comply with software development patterns and standards, produce economic value and lead to corporate performance improvement. In this paper, we investigate the relationship between quality maturity levels and labor productivity, using a data set containing 687 Brazilian software firms. We study here the relationship between labor productivity, as measured through the annual gross revenue per worker ratio, and quality levels, which were appraised from 2006 to 2012 according to two distinct software process improvement models: MPS.BR and CMMI. We perform independent statistical tests using appraisals carried out according to each of these models, consequently obtaining a data set with as many observations as possible, in order to seek strong support for our research. We first show that MPS.BR and CMMI appraised quality maturity levels are correlated, but we find no statistical evidence that they are related to higher labor productivity or productivity growth. On the contrary, we present evidence suggesting that average labor productivity is higher in software companies without appraised quality levels. Moreover, our analyses suggest that companies with appraised quality maturity levels are more or less productive depending on factors such as their business nature, main origin of capital and maintained quality level. © 2016, Springer Science+Business Media New York."
"Tosun A., Bener A.B., Akbarinasaji S.",A systematic literature review on the applications of Bayesian networks to predict software quality,2017,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948125967&doi=10.1007%2fs11219-015-9297-z&partnerID=40&md5=afee43bb29c0fd48b13f52c1eb165e36,"Bayesian networks (BN) have been used for decision making in software engineering for many years. In other fields such as bioinformatics, BNs are rigorously evaluated in terms of the techniques that are used to build the network structure and to learn the parameters. We extend our prior mapping study to investigate the extent to which contextual and methodological details regarding BN construction are reported in the studies. We conduct a systematic literature review on the applications of BNs to predict software quality. We focus on more detailed questions regarding (1) dataset characteristics, (2) techniques used for parameter learning, (3) techniques used for structure learning, (4) use of tools, and (5) model validation techniques. Results on ten primary studies show that BNs are mostly built based on expert knowledge, i.e. structure and prior distributions are defined by experts, whereas authors benefit from BN tools and quantitative data to validate their models. In most of the papers, authors do not clearly explain their justification for choosing a specific technique, and they do not compare their proposed BNs with other machine learning approaches. There is also a lack of consensus on the performance measures to validate the proposed BNs. Compared to other domains, the use of BNs is still very limited and current publications do not report enough details to replicate the studies. We propose a framework that provides a set of guidelines for reporting the essential contextual and methodological details of BNs. We believe such a framework would be useful to replicate and extend the work on BNs. © 2015, Springer Science+Business Media New York."
"Mkaouer M.W., Kessentini M., Bechikh S., Ó Cinnéide M., Deb K.",On the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach,2016,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951756385&doi=10.1007%2fs10664-015-9414-4&partnerID=40&md5=9b6ecf0a25cc8eb003e321aff9f5b63c,"Search-based software engineering (SBSE) solutions are still not scalable enough to handle high-dimensional objectives space. The majority of existing work treats software engineering problems from a single or bi-objective point of view, where the main goal is to maximize or minimize one or two objectives. However, most software engineering problems are naturally complex in which many conflicting objectives need to be optimized. Software refactoring is one of these problems involving finding a compromise between several quality attributes to improve the quality of the system while preserving the behavior. To this end, we propose a novel representation of the refactoring problem as a many-objective one where every quality attribute to improve is considered as an independent objective to be optimized. In our approach based on the recent NSGA-III algorithm, the refactoring solutions are evaluated using a set of 8 distinct objectives. We evaluated this approach on one industrial project and seven open source systems. We compared our findings to: several other many-objective techniques (IBEA, MOEA/D, GrEA, and DBEA-Eps), an existing multi-objective approach a mono-objective technique and an existing refactoring technique not based on heuristic search. Statistical analysis of our experiments over 31 runs shows the efficiency of our approach. © 2015, Springer Science+Business Media New York."
"McIntosh S., Kamei Y., Adams B., Hassan A.E.",An empirical study of the impact of modern code review practices on software quality,2016,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928384936&doi=10.1007%2fs10664-015-9381-9&partnerID=40&md5=4ccadde0c9552d2747cfa6bdf80ff3ca,"Software code review, i.e., the practice of having other team members critique changes to a software system, is a well-established best practice in both open source and proprietary software domains. Prior work has shown that formal code inspections tend to improve the quality of delivered software. However, the formal code inspection process mandates strict review criteria (e.g., in-person meetings and reviewer checklists) to ensure a base level of review quality, while the modern, lightweight code reviewing process does not. Although recent work explores the modern code review process, little is known about the relationship between modern code review practices and long-term software quality. Hence, in this paper, we study the relationship between post-release defects (a popular proxy for long-term software quality) and: (1) code review coverage, i.e., the proportion of changes that have been code reviewed, (2) code review participation, i.e., the degree of reviewer involvement in the code review process, and (3) code reviewer expertise, i.e., the level of domain-specific expertise of the code reviewers. Through a case study of the Qt, VTK, and ITK projects, we find that code review coverage, participation, and expertise share a significant link with software quality. Hence, our results empirically confirm the intuition that poorly-reviewed code has a negative impact on software quality in large systems using modern reviewing tools. © 2015, Springer Science+Business Media New York."
"Janicijevic I., Krsmanovic M., Zivkovic N., Lazarevic S.",Software quality improvement: a model based on managing factors impacting software quality,2016,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908118810&doi=10.1007%2fs11219-014-9257-z&partnerID=40&md5=49441ef38876a3665b52cb6086473831,"Software quality is recognized as being very significant for achieving competitiveness in the software industry, so improvements in this area are gaining increasing importance. Software quality improvements can only be achieved by managing all of the factors that influence it. However, in a real business system, there are a great number of factors impacting software quality, while the processes are stochastic and resources are limited, so economic data should also be taken into consideration. This paper uses a Markov chain and proposes a systematic framework for modelling the stochastic processes of a quality management system and selection of the optimum set of factors impacting software quality. A methodology is presented for managing the factors that affect software quality with an illustrative hypothetical example for convenience of application of the proposed methodology. © 2014, Springer Science+Business Media New York."
Boehm B.,Improving and balancing software qualities,2016,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026633467&doi=10.1145%2f2889160.2891049&partnerID=40&md5=6d99ef500aabca2de5eabfb37df2b2d4,"This Technical Briefing describes the nature of Software Qualities (SQs), ilities, or non-functional requirements (reliability, usability, affordability, etc.), and discusses the importance of understanding their nature and interrelationships, and of bringing them into balance in the practice of software engineering. The relevance and timeliness of this topic reflects the current and future trends toward more software-intensive systems, with greater complexity, autonomy, speed of change, and need for interoperability within systems of systems, given the frequent system shortfalls and overruns that occur when their SQ balance is not achieved. It discusses the weaknesses of current SQ standards and guidance, and summarizes research toward strengthening current SQ definitions and relationships. This includes a set of initial SQ ontology elements and relationships, examples of their application to some key SQs, an identification of further research and development needed to make the ontology fully useful and evolvable, and the nature of an international collaborative effort to help improve current practices via a Qualipedia for accessing the evolving body of knowledge for improving SQ engineering. © 2016 Author."
Salman I.,Cognitive biases in software quality and testing,2016,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018633964&doi=10.1145%2f2889160.2889265&partnerID=40&md5=2e6ecd5166fb1360d1af9f67d9b1d1f9,"Humans are an integral entity for performing software quality and testing activities. The quality is compromised when human-thought process deviates from the laws of rational thinking, referred to as cognitive biases. The work carried out so far from this perspective in software quality and testing is very scarce and is limited to one cognitive bias only. This work aims to explore the phenomenon of cognitive biases in software quality and testing in more detail. Furthermore, investigating the factors that exist in an organisational context and that trigger the biases, which in turn deteriorate the quality of software, is also the focus of this work. Acquiring the knowledge of cognitive biases and the triggering factors will help in circumventing them, thus improving software quality. © 2016 ACM."
"Thongtanunam P., McIntosh S., Hassan A.E., Iida H.",Revisiting code ownership and its relationship with software quality in the scope of modern code review,2016,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971482984&doi=10.1145%2f2884781.2884852&partnerID=40&md5=0c2da8fa587f2d260b605b676b5a2c31,"Code ownership establishes a chain of responsibility for modules in large software systems. Although prior work uncovers a link between code ownership heuristics and software quality, these heuristics rely solely on the authorship of code changes. In addition to authoring code changes, developers also make important contributions to a module by reviewing code changes. Indeed, recent work shows that reviewers are highly active in modern code review processes, often suggesting alternative solutions or providing updates to the code changes. In this paper, we complement traditional code ownership heuristics using code review activity. Through a case study of six releases of the large Qt and OpenStack systems, we find that: (1) 67%-86% of developers did not author any code changes for a module, but still actively contributed by reviewing 21%-39% of the code changes, (2) code ownership heuristics that are aware of reviewing activity share a relationship with software quality, and (3) the proportion of reviewers without expertise shares a strong, increasing relationship with the likelihood of having post-release defects. Our results suggest that reviewing activity captures an important aspect of code ownership, and should be included in approximations of it in future studies. © 2016 ACM."
"Wang S., Ali S., Yue T., Li Y., Liaaen M.",A practical guide to select quality indicators for assessing pareto-based search algorithms in search-based software engineering,2016,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971412816&doi=10.1145%2f2884781.2884880&partnerID=40&md5=fb106f940fea5f845deddb5ac287de81,"Many software engineering problems are multi-objective in nature, which has been largely recognized by the Search-based Software Engineering (SBSE) community. In this regard, Paretobased search algorithms, e.g., Non-dominated Sorting Genetic Algorithm II, have already shown good performance for solving multi-objective optimization problems. These algorithms produce Pareto fronts, where each Pareto front consists of a set of nondominated solutions. Eventually, a user selects one or more of the solutions from a Pareto front for their specific problems. A key challenge of applying Pareto-based search algorithms is to select appropriate quality indicators, e.g., hypervolume, to assess the quality of Pareto fronts. Based on the results of an extended literature review, we found that the current literature and practice in SBSE lacks a practical guide for selecting quality indicators despite a large number of published SBSE works. In this direction, the paper presents a practical guide for the SBSE community to select quality indicators for assessing Pareto-based search algorithms in different software engineering contexts. The practical guide is derived from the following complementary theoretical and empirical methods: 1) key theoretical foundations of quality indicators; 2) evidence from an extended literature review; and 3) evidence collected from an extensive experiment that was conducted to evaluate eight quality indicators from four different categories with six Pareto-based search algorithms using three real industrial problems from two diverse domains. © 2016 ACM."
"Chatzipetrou P., Angelis L., Barney S., Wohlin C.",An experience-based framework for evaluating alignment of software quality goals,2015,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028193608&doi=10.1007%2fs11219-014-9251-5&partnerID=40&md5=dbcf765656760d5ef5d16996f0b82b9f,"Efficient quality management of software projects requires knowledge of how various groups of stakeholders involved in software development prioritize the product and project goals. Agreements or disagreements among members of a team may originate from inherent groupings, depending on various professional or other characteristics. These agreements are not easily detected by conventional practices (discussions, meetings, etc.) since the natural language expressions are often obscuring, subjective, and prone to misunderstandings. It is therefore essential to have objective tools that can measure the alignment among the members of a team; especially critical for the software development is the degree of alignment with respect to the prioritization goals of the software product. The paper proposes an experience-based framework of statistical and graphical techniques for the systematic study of prioritization alignment, such as hierarchical cluster analysis, analysis of cluster composition, correlation analysis, and closest agreement-directed graph. This framework can provide a thorough and global picture of a team’s prioritization perspective and can potentially aid managerial decisions regarding team composition and leadership. The framework is applied and illustrated in a study related to global software development where 65 individuals in different roles, geographic locations and professional relationships with a company, prioritize 24 goals from individual perception of the actual situation and for an ideal situation. © 2014, Springer Science+Business Media New York."
"Jabangwe R., Börstler J., Petersen K.",Handover of managerial responsibilities in global software development: a case study of source code evolution and quality,2015,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944511169&doi=10.1007%2fs11219-014-9247-1&partnerID=40&md5=ca9b6b9aefe9dfad177d3fb3e573f0c5,"Studies report on the negative effect on quality in global software development (GSD) due to communication and coordination-related challenges. However, empirical studies reporting on the magnitude of the effect are scarce. This paper presents findings from an embedded explanatory case study on the change in quality over time, across multiple releases, for products that were developed in a GSD setting. The GSD setting involved periods of distributed development between geographically dispersed sites as well as a handover of project management responsibilities between the involved sites. Investigations were performed on two medium-sized products from a company that is part of a large multinational corporation. Quality is investigated quantitatively using defect data and measures that quantify two source code properties, size and complexity. Observations were triangulated with subjective views from company representatives. There were no observable indications that the distribution of work or handover of project management responsibilities had an impact on quality on both products. Among the product-, process- and people-related success factors, we identified well-designed product architectures, early handover planning and support from the sending site to the receiving site after the handover and skilled employees at the involved sites. Overall, these results can be useful input for decision-makers who are considering distributing development work between globally dispersed sites or handing over project management responsibilities from one site to another. Moreover, our study shows that analyzing the evolution of size and complexity properties of a product’s source code can provide valuable information to support decision-making during similar projects. Finally, the strategy used by the company to relocate responsibilities can also be considered as an alternative for software transfers, which have been linked with a decline in efficiency, productivity and quality. © 2014, Springer Science+Business Media New York."
"Carver J.C., Yamashita A., Minku L., Habayeb M., Kocak S.A.","Software Quality, Energy Awareness, and More",2015,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946549609&doi=10.1109%2fMS.2015.127&partnerID=40&md5=246514c9e82cfd6ead50e7defb1571f6,"This article discusses six papers presented at events connected with the 2015 International Conference on Software Engineering. The papers cover organizational factors and software quality, microclones, big data platforms, energy-aware commits, open source software architecture, and requirements engineering. © 2015 IEEE."
"Lavallée M., Robillard P.N.",Why good developers write bad code: An observational case study of the impacts of organizational factors on software quality,2015,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951838553&doi=10.1109%2fICSE.2015.83&partnerID=40&md5=010ff95af592509e0c365f250fa510c3,"How can organizational factors such as structure and culture have an impact on the working conditions of developers? This study is based on ten months of observation of an in-house software development project within a large telecommunications company. The observation was conducted during mandatory weekly status meetings, where technical and managerial issues were raised and discussed. Preliminary results show that many decisions made under the pressure of certain organizational factors negatively affected software quality. This paper describes cases depicting the complexity of organizational factors and reports on ten issues that have had a negative impact on quality, followed by suggested avenues for corrective action. © 2015 IEEE."
"Suryanarayana G., Sharma T., Samarthyam G.",Software Process versus Design Quality: Tug of War?,2015,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962249336&doi=10.1109%2fMS.2015.87&partnerID=40&md5=2196180ec3af8de0dddfdb701359a10b,"Software processes and design quality are inextricably intertwined. So, developers must consider their impact on each other to ensure a high-quality design. © 2015 IEEE."
"Galinac Grbac T., Car Ž., Huljenić D.",A quality cost reduction model for large-scale software development,2015,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925839331&doi=10.1007%2fs11219-014-9240-8&partnerID=40&md5=c1098d690d854415c6385a80aad0b3a6,"Understanding quality costs is recognized as a prerequisite for decreasing the variability of the success of software development projects. This paper presents an empirical quality cost reduction (QCR) model to support the decision-making process for additional investment in the early phases of software verification. The main idea of the QCR model is to direct additional investment into software units that have some fault-slip potential in their later verification phases, with the aim of reducing costs and increasing product quality. The fault-slip potential of a software unit within a system is determined by analogy with historical projects. After a preliminary study on a sample of software units, which proves that we can lower quality costs with additional investment into particular verification activities, we examine the effectiveness of the proposed QCR model using real project data. The results show that applying the model produces a positive business case, meaning that the model lowers quality costs and increases quality, resulting in economic benefit. The potential to reduce quality costs is growing significantly with the evolution of software systems and the reuse of their software units. The proposed model is the result of a research project performed at Ericsson. © 2014, Springer Science+Business Media New York."
"Khomh F., Adams B., Dhaliwal T., Zou Y.",Understanding the impact of rapid releases on software quality: The case of firefox,2015,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928707650&doi=10.1007%2fs10664-014-9308-x&partnerID=40&md5=21208201add0e79aae5c43c95cf46dcf,"Many software companies are shifting from the traditional multi-month release cycle to shorter release cycles. For example, Google Chrome and Mozilla Firefox release new versions every 6 weeks. These shorter release cycles reduce the users’ waiting time for a new release and offer better feedback and marketing opportunities to companies, but it is unclear if the quality of the software product improves as well, since developers and testers are under more pressure. In this paper, we extend our previous empirical study of Mozilla Firefox on the impact of rapid releases on quality assurance with feedback by Mozilla project members. The study compares crash rates, median uptime, and the proportion of pre- and post-release bugs in traditional releases with those in rapid releases, and we also analyze the source code changes made by developers to identify potential changes in the development process. We found that (1) with shorter release cycles, users do not experience significantly more pre- or post-release bugs (percentage-wise) and (2) bugs are fixed faster, yet (3) users experience these bugs earlier during software execution (the program crashes earlier). Increased integration activity and propagation of harder bugs to later versions account for some of these findings. Overall, our case study suggests that a clear release engineering process with thorough automation is one of the major challenges when switching to rapid releases. © 2014, Springer Science+Business Media New York."
"Shang W., Nagappan M., Hassan A.E.",Studying the relationship between logging characteristics and the code quality of platform software,2015,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922001381&doi=10.1007%2fs10664-013-9274-8&partnerID=40&md5=3e2698304867833acfe9c475bacdcf9f,"Platform software plays an important role in speeding up the development of large scale applications. Such platforms provide functionalities and abstraction on which applications can be rapidly developed and easily deployed. Hadoop and JBoss are examples of popular open source platform software. Such platform software generate logs to assist operators in monitoring the applications that run on them. These logs capture the doubts, concerns, and needs of developers and operators of platform software. We believe that such logs can be used to better understand code quality. However, logging characteristics and their relation to quality has never been explored. In this paper, we sought to empirically study this relation through a case study on four releases of Hadoop and JBoss. Our findings show that files with logging statements have higher post-release defect densities than those without logging statements in 7 out of 8 studied releases. Inspired by prior studies on code quality, we defined log-related product metrics, such as the number of log lines in a file, and log-related process metrics such as the number of changed log lines. We find that the correlations between our log-related metrics and post-release defects are as strong as their correlations with traditional process metrics, such as the number of pre-release defects, which is known to be one the metrics with the strongest correlation with post-release defects. We also find that log-related metrics can complement traditional product and process metrics resulting in up to 40 % improvement in explanatory power of defect proneness. Our results show that logging characteristics provide strong indicators of defect-prone source code files. However, we note that removing logs is not the answer to better code quality. Instead, our results show that it might be the case that developers often relay their concerns about a piece of code through logs. Hence, code quality improvement efforts (e.g., testing and inspection) should focus more on the source code files with large amounts of logs or with large amounts of log churn. © 2013, Springer Science+Business Media New York."
"Poth A., Sunyaev A.",Effective quality management: Value- and risk-based software quality management,2014,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910155482&doi=10.1109%2fMS.2013.138&partnerID=40&md5=2e01d1bfde5a1b581eda25b4636cfe58,"Software quality management (SQM) must effectively deploy resources for quality assurance activities to reflect the achieved product quality. So, quality managers should exploit their creative freedom to direct their courses of action within the economic constraints. Effective Quality Management can increase SQM effectiveness. This value- and risk-based method is applicable for software developers, their customers, and users. This is due to its product function orientation and the independence of the software development procedures. © 1984-2012 IEEE."
"Gleirscher M., Golubitskiy D., Irlbeck M., Wagner S.",Introduction of static quality analysis in small- and medium-sized software enterprises: experiences from technology transfer,2014,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927804487&doi=10.1007%2fs11219-013-9217-z&partnerID=40&md5=96b5166ac6f386a4db36845b014b836d,"Today, small- and medium-sized enterprises (SMEs) in the software industry face major challenges. Their resource constraints require high efficiency in development. Furthermore, quality assurance (QA) measures need to be taken to mitigate the risk of additional, expensive effort for bug fixes or compensations. Automated static analysis (ASA) can reduce this risk because it promises low application effort. SMEs seem to take little advantage of this opportunity. Instead, they still mainly rely on the dynamic analysis approach of software testing. In this article, we report on our experiences from a technology transfer project. Our aim was to evaluate the results static analysis can provide for SMEs as well as the problems that occur when introducing and using static analysis in SMEs. We analysed five software projects from five collaborating SMEs using three different ASA techniques: code clone detection, bug pattern detection and architecture conformance analysis. Following the analysis, we applied a quality model to aggregate and evaluate the results. Our study shows that the effort required to introduce ASA techniques in SMEs is small (mostly below one person-hour each). Furthermore, we encountered only few technical problems. By means of the analyses, we could detect multiple defects in production code. The participating companies perceived the analysis results to be a helpful addition to their current QA and will include the analyses in their QA process. With the help of the Quamoco quality model, we could efficiently aggregate and rate static analysis results. However, we also encountered a partial mismatch with the opinions of the SMEs. We conclude that ASA and quality models can be a valuable and affordable addition to the QA process of SMEs. © Springer Science+Business Media New York 2013."
"Zhang G., Ye H., Lin Y.",Quality attribute modeling and quality aware product configuration in software product lines,2014,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875049200&doi=10.1007%2fs11219-013-9197-z&partnerID=40&md5=ad822ef7f6b285eb153f76658a503708,"In software product line engineering, the customers mostly concentrate on the functionalities of the target product during product configuration. The quality attributes of a target product, such as security and performance, are often assessed until the final product is generated. However, it might be very costly to fix the problem if it is found that the generated product cannot satisfy the customers’ quality requirements. Although the quality of a generated product will be affected by all the life cycles of product development, feature-based product configuration is the first stage where the estimation or prediction of the quality attributes should be considered. As we know, the key issue of predicting the quality attributes for a product configured from feature models is to measure the interdependencies between functional features and quality attributes. The current existing approaches have several limitations on this issue, such as requiring real products for the measurement or involving domain experts’ efforts. To overcome these limitations, we propose a systematic approach of modeling quality attributes in feature models based on domain experts’ judgments using the analytic hierarchical process (AHP) and conducting quality aware product configuration based on the captured quality knowledge. Domain experts’ judgments are adapted to avoid generating the real products for quality evaluation, and AHP is used to reduce domain experts’ efforts involved in the judgments. A prototype tool is developed to implement the concepts of the proposed approach, and a formal evaluation is carried out based on a large-scale case study. © 2013, Springer Science+Business Media New York."
"Breu R., Kuntzmann-Combelles A., Felderer M.",New perspectives on software quality,2014,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896288088&doi=10.1109%2fMS.2014.9&partnerID=40&md5=6e2e5fb2f50c47f1203ae65ab9be581d,"This special issue, owing to its fundamental software quality focus, comprises a collection of diverse articles that address the challenges and directions for software quality research. The Web extra at http://youtu.be/ T7V4RSr1KEE is an audio interview in which Davide Falessi speaks with guest editors Annie Kuntzmann-Combelles, Michael Felderer, and Ruth Breu about methods for improving software quality management, testing, and security on intelligent and interconnected devices. © 1984-2012 IEEE."
Thakurta R.,A framework for prioritization of quality requirements for inclusion in a software project,2013,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883450871&doi=10.1007%2fs11219-012-9188-5&partnerID=40&md5=cd6f505b77e01c4b9a0c58ebce43ccf2,"Non-functional requirements (NFRs) determine the characteristics of a software product or service as a whole. The research described in this paper presents a quantitative framework involving respondents of both the project and the business organization, in order to determine the priority of a list of NFRs to be considered for implementation during a software development. The framework also provides a quantitative basis for evaluating the extent of value addition that can be achieved while deciding upon whether or not to consider a particular non-functional requirement for inclusion to the project's requirement set. The assessment process also indicates the extent to which different business values are perceived important by representatives of business organizations, and their perception of the importance of the different NFRs. The work distinguishes from others by explicitly considering dependencies among NFRs in the evaluation process. The final results are expected to be beneficial to both the business and the project organization by identifying and implementing the desired NFRs that contribute to business value in a cost-effective manner. © 2012 Springer Science+Business Media New York."
Kouroshfar E.,Studying the effect of co-change dispersion on software quality,2013,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886429987&doi=10.1109%2fICSE.2013.6606741&partnerID=40&md5=f9b5aa44f572315b1cd1c58858d1d1a6,"Software change history plays an important role in measuring software quality and predicting defects. Co-change metrics such as number of files changed together has been used as a predictor of bugs. In this study, we further investigate the impact of specific characteristics of co-change dispersion on software quality. Using statistical regression models we show that co-changes that include files from different subsystems result in more bugs than co-changes that include files only from the same subsystem. This can be used to improve bug prediction models based on co-changes. © 2013 IEEE."
"Samarthyam G., Suryanarayana G., Sharma T., Gupta S.",MIDAS: A design quality assessment method for industrial software,2013,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886396370&doi=10.1109%2fICSE.2013.6606640&partnerID=40&md5=ad0d81ee2973d5ee478e587bb1b55aa5,"Siemens Corporate Development Center Asia Australia (CT DC AA) develops and maintains software applications for the Industry, Energy, Healthcare, and Infrastructure & Cities sectors of Siemens. The critical nature of these applications necessitates a high level of software design quality. A survey of software architects indicated a low level of satisfaction with existing design assessment practices in CT DC AA and highlighted several shortcomings of existing practices. To address this, we have developed a design assessment method called MIDAS (Method for Intensive Design ASsessments). MIDAS is an expert-based method wherein manual assessment of design quality by experts is directed by the systematic application of design analysis tools through the use of a three view-model consisting of design principles, project-specific constraints, and an 'ility'-based quality model. In this paper, we describe the motivation for MIDAS, its design, and its application to three projects in CT DC AA. We believe that the insights from our MIDAS experience not only provide useful pointers to other organizations and practitioners looking to assess and improve software design quality but also suggest research questions for the software engineering community to explore. © 2013 IEEE."
Guerrouj L.,Normalizing source code vocabulary to support program comprehension and software quality,2013,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886391532&doi=10.1109%2fICSE.2013.6606723&partnerID=40&md5=191e7233ea6777ff76ebefbf832bbda5,"The literature reports that source code lexicon plays a paramount role in program comprehension, especially when software documentation is scarce, outdated or simply not available. In source code, a significant proportion of vocabulary can be either acronyms and-or abbreviations or concatenation of terms that can not be identified using consistent mechanisms such as naming conventions. It is, therefore, essential to disambiguate concepts conveyed by identifiers to support program comprehension and reap the full benefit of Information Retrieval-based techniques (e.g., feature location and traceability) whose linguistic information (i.e., source code identifiers and comments) used across all software artifacts (e.g., requirements, design, change requests, tests, and source code) must be consistent. To this aim, we propose source code vocabulary normalization approaches that exploit contextual information to align the vocabulary found in the source code with that found in other software artifacts. We were inspired in the choice of context levels by prior works and by our findings. Normalization consists of two tasks: splitting and expansion of source code identifiers. We also investigate the effect of source code vocabulary normalization approaches on software maintenance tasks. Results of our evaluation show that our contextual-aware techniques are accurate and efficient in terms of computation time than state of the art alternatives. In addition, our findings reveal that feature location techniques can benefit from vocabulary normalization when no dynamic information is available. © 2013 IEEE."
Brandtner M.,Fostering software quality assessment,2013,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886382849&doi=10.1109%2fICSE.2013.6606725&partnerID=40&md5=9e042076903be6351b3b97be6a877cb3,"Software quality assessment shall monitor and guide the evolution of a system based on quality measurements. This continuous process should ideally involve multiple stakeholders and provide adequate information for each of them to use. We want to support an effective selection of quality measurements based on the type of software and individual information needs of the involved stakeholders. We propose an approach that brings together quality measurements and individual information needs for a context-sensitive tailoring of information related to a software quality assessment. We address the following research question: How can we better support different stakeholders in the quality assessment of a software system? For that we will devise theories, models, and prototypes to capture their individual information needs, tailor information from software repositories to these needs, and enable a contextual analysis of the quality aspects. Such a context-sensitive tailoring will provide a effective and individual view on the latest development trends in a project. We outline the milestones as well as evaluation approaches in this paper. © 2013 IEEE."
"Çalıklı G., Bener A.B.",Influence of confirmation biases of developers on software quality: An empirical study,2013,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875477125&doi=10.1007%2fs11219-012-9180-0&partnerID=40&md5=cc6f8f69000fcbb792e93b5cc875f69d,"The thought processes of people have a significant impact on software quality, as software is designed, developed and tested by people. Cognitive biases, which are defined as patterned deviations of human thought from the laws of logic and mathematics, are a likely cause of software defects. However, there is little empirical evidence to date to substantiate this assertion. In this research, we focus on a specific cognitive bias, confirmation bias, which is defined as the tendency of people to seek evidence that verifies a hypothesis rather than seeking evidence to falsify a hypothesis. Due to this confirmation bias, developers tend to perform unit tests to make their program work rather than to break their code. Therefore, confirmation bias is believed to be one of the factors that lead to an increased software defect density. In this research, we present a metric scheme that explores the impact of developers' confirmation bias on software defect density. In order to estimate the effectiveness of our metric scheme in the quantification of confirmation bias within the context of software development, we performed an empirical study that addressed the prediction of the defective parts of software. In our empirical study, we used confirmation bias metrics on five datasets obtained from two companies. Our results provide empirical evidence that human thought processes and cognitive aspects deserve further investigation to improve decision making in software development for effective process management and resource allocation. © 2012 Springer Science+Business Media, LLC."
"Bettenburg N., Hassan A.E.",Studying the impact of social interactions on software quality,2013,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880701721&doi=10.1007%2fs10664-012-9205-0&partnerID=40&md5=6196585ec2ffd6929a1369e0a035a33c,"Correcting software defects accounts for a significant amount of resources in a software project. To make best use of testing efforts, researchers have studied statistical models to predict in which parts of a software system future defects are likely to occur. By studying the mathematical relations between predictor variables used in these models, researchers can form an increased understanding of the important connections between development activities and software quality. Predictor variables used in past top-performing models are largely based on source code-oriented metrics, such as lines of code or number of changes. However, source code is the end product of numerous interlaced and collaborative activities carried out by developers. Traces of such activities can be found in the various repositories used to manage development efforts. In this paper, we develop statistical models to study the impact of social interactions in a software project on software quality. These models use predictor variables based on social information mined from the issue tracking and version control repositories of two large open-source software projects. The results of our case studies demonstrate the impact of metrics from four different dimensions of social interaction on post-release defects. Our findings show that statistical models based on social information have a similar degree of explanatory power as traditional models. Furthermore, our results demonstrate that social information does not substitute, but rather augments traditional source code-based metrics used in defect prediction models. © 2012 Springer Science+Business Media, LLC."
"Li J., Stalhane T., Conradi R., Kristiansen J.M.W.",Enhancing defect tracking systems to facilitate software quality improvement,2012,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863297555&doi=10.1109%2fMS.2011.24&partnerID=40&md5=e741c2dc3eecffec2fa5e97a54b547a6,"For projects that rely on empirical process control and deliver frequently working versions of software, developers and project managers regularly need to examine the status of their software quality. This study illustrates that simple goal-oriented changes or extensions to the existing data of projects' respective defect tracking systems could provide valuable and prompt information to improve their software quality assessment and assurance. © 2012 IEEE."
"Montagud S., Abrahão S., Insfran E.",A systematic review of quality attributes and measures for software product lines,2012,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865626740&doi=10.1007%2fs11219-011-9146-7&partnerID=40&md5=33b25cd0a25fc09685e06cbc9c988f14,"It is widely accepted that software measures provide an appropriate mechanism for understanding, monitoring, controlling, and predicting the quality of software development projects. In software product lines (SPL), quality is even more important than in a single software product since, owing to systematic reuse, a fault or an inadequate design decision could be propagated to several products in the family. Over the last few years, a great number of quality attributes and measures for assessing the quality of SPL have been reported in literature. However, no studies summarizing the current knowledge about them exist. This paper presents a systematic literature review with the objective of identifying and interpreting all the available studies from 1996 to 2010 that present quality attributes and/or measures for SPL. These attributes and measures have been classified using a set of criteria that includes the life cycle phase in which the measures are applied; the corresponding quality characteristics; their support for specific SPL characteristics (e. g., variability, compositionality); the procedure used to validate the measures, etc. We found 165 measures related to 97 different quality attributes. The results of the review indicated that 92% of the measures evaluate attributes that are related to maintainability. In addition, 67% of the measures are used during the design phase of Domain Engineering, and 56% are applied to evaluate the product line architecture. However, only 25% of them have been empirically validated. In conclusion, the results provide a global vision of the state of the research within this area in order to help researchers in detecting weaknesses, directing research efforts, and identifying new research lines. In particular, there is a need for new measures with which to evaluate both the quality of the artifacts produced during the entire SPL life cycle and other quality characteristics. There is also a need for more validation (both theoretical and empirical) of existing measures. In addition, our results may be useful as a reference guide for practitioners to assist them in the selection or the adaptation of existing measures for evaluating their software product lines. © 2011 Springer Science+Business Media, LLC."
"Baggen R., Correia J.P., Schill K., Visser J.",Standardized code quality benchmarking for improving software maintainability,2012,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860465895&doi=10.1007%2fs11219-011-9144-9&partnerID=40&md5=042a7624f2cb95e1a97643ef8e0f9071,"We provide an overview of the approach developed by the Software Improvement Group for code analysis and quality consulting focused on software maintainability. The approach uses a standardized measurement model based on the ISO/IEC 9126 definition of maintainability and source code metrics. Procedural standardization in evaluation projects further enhances the comparability of results. Individual assessments are stored in a repository that allows any system at hand to be compared to the industrywide state of the art in code quality and maintainability. When a minimum level of software maintainability is reached, the certification body of TÜV Informationstechnik GmbH issues a Trusted Product Maintainability certificate for the software product. © Springer Science+Business Media, LLC 2011."
"Becker P., Lew P., Olsina L.",Strategy to improve quality for software applications: A process view,2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960589413&doi=10.1145%2f1987875.1987897&partnerID=40&md5=697727eaef77cbebdc3618cbb98affc8,"Each organization devoted to developing software/web applications should have as one of its ultimate goals to improve the quality in use of its products. In order to accomplish this, first it has to understand the quality of the current product version and then make appropriate changes to increase the quality of the new version if improvement actions were needed. For this purpose, we have developed a specific strategy called SIQinU (Strategy for understanding and Improving Quality in Use), which allows recognizing problems of quality in use through evaluation and proposes product improvements by understanding and making changes on product attributes. Hence by re-evaluating quality in use of the new version, improvement gains can be gauged. SIQinU is in alignment with GOCAME (Goal-Oriented Context-Aware Measurement and Evaluation), a multi-purpose generic strategy previously developed for measurement and evaluation which relies on: a conceptual framework (with ontological base), a process, and methods and tools. Since the process aspect is paramount in defining SIQinU - given the amount of phases and activities - in this paper we model the functional and behavioral process views illustrating them with excerpts of a real case study. © 2011 ACM."
"Koziolek H., Schlich B., Bilich C., Weiss R., Becker S., Krogmann K., Trifu M., Mirandola R., Koziolek A.",An industrial case study on quality impact prediction for evolving service-oriented software,2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959911405&doi=10.1145%2f1985793.1985902&partnerID=40&md5=e03e95c9edbcc73b224aa5c8d203d93a,"Systematic decision support for architectural design decisions is a major concern for software architects of evolving service-oriented systems. In practice, architects often analyse the expected performance and reliability of design alternatives based on prototypes or former experience. Model-driven prediction methods claim to uncover the tradeoffs between different alternatives quantitatively while being more cost-effective and less error-prone. However, they often suffer from weak tool support and focus on single quality attributes. Furthermore, there is limited evidence on their effectiveness based on documented industrial case studies. Thus, we have applied a novel, model-driven prediction method called Q-ImPrESS on a large-scale process control system consisting of several million lines of code from the automation domain to evaluate its evolution scenarios. This paper reports our experiences with the method and lessons learned. Benefits of Q-ImPrESS are the good architectural decision support and comprehensive tool framework, while one drawback is the time-consuming data collection. © 2011 ACM."
"Ramasubbu N., Cataldo M., Balan R.K., Herbsleb J.D.","Configuring global software teams: A multi-company analysis of project productivity, quality, and profits",2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959893269&doi=10.1145%2f1985793.1985830&partnerID=40&md5=cccb96b63639e9e080e257f0d4e1fd13,"In this paper, we examined the impact of project-level configurational choices of globally distributed software teams on project productivity, quality, and profits. Our analysis used data from 362 projects of four different firms. These projects spanned a wide range of programming languages, application domain, process choices, and development sites spread over 15 countries and 5 continents. Our analysis revealed fundamental tradeoffs in choosing configurational choices that are optimized for productivity, quality, and/or profits. In particular, achieving higher levels of productivity and quality require diametrically opposed configurational choices. In addition, creating imbalances in the expertise and personnel distribution of project teams significantly helps increase profit margins. However, a profit-oriented imbalance could also significantly affect productivity and/or quality outcomes. Analyzing these complex tradeoffs, we provide actionable managerial insights that can help software firms and their clients choose configurations that achieve desired project outcomes in globally distributed software development. © 2011 ACM."
Shihab E.,Pragmatic prioritization of software quality assurance efforts,2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959864680&doi=10.1145%2f1985793.1986007&partnerID=40&md5=0e2ecdae077441ec1422a8aaa4bbf673,"A plethora of recent work leverages historical data to help practitioners better prioritize their software quality assurance efforts. However, the adoption of this prior work in practice remains low. In our work, we identify a set of challenges that need to be addressed to make previous work on quality assurance prioritization more pragmatic. We outline four guidelines that address these challenges to make prior work on software quality assurance more pragmatic: 1) Focused Granularity (i.e., small prioritization units), 2) Timely Feedback (i.e., results can be acted on in a timely fashion), 3) Estimate Effort (i.e., estimate the time it will take to complete tasks), and 4) Evaluate Generality (i.e., evaluate findings across multiple projects and multiple domains). We present two approaches, at the code and change level, that demonstrate how prior approaches can be more pragmatic. © 2011 Author."
"Turnu I., Concas G., Marchesi M., Tonelli R.",The fractal dimension metric and its use to assess object-oriented software quality,2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959820792&doi=10.1145%2f1985374.1985391&partnerID=40&md5=b5b6e37a0c9c5c579dc5012d4a9d2036,"We present a study were software systems are considered as complex networks which have a self-similar structure under a length-scale transformation. On such complex software networks we computed a self-similar coefficient, also known as fractal dimension, using ""the box counting method"". We analyzed various releases of the publically available Eclipse software systems, calculating the fractal dimension for twenty sub-projects, randomly chosen, for every release, as well as for each release as a whole. Our results display an overall consistency among the sub-projects and among all the analyzed releases. We found a very good correlation between the fractal dimension and the number of bugs for Eclipse and for twenty sub-projects. Since the fractal dimension is just a scalar number that characterizes a whole system, while complexity and quality metrics are in general computed on every system module, this result suggests that the fractal dimension could be considered as a global quality metric for large software systems. Our results need however to be confirmed for other large software systems. © 2011 ACM."
Shepperd M.,Data quality: Cinderella at the software metrics ball?,2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959818838&doi=10.1145%2f1985374.1985376&partnerID=40&md5=834ab31572e7638d734a4a2b47d48039,"In this keynote I explore what exactly do we mean by data quality, techniques to assess data quality and the very significant challenges that poor data quality can pose. I believe we neglect data quality at our peril since - whether we like it or not - our research results are founded upon data and our assumptions that data quality issues do not confound our results. A systematic review of the literature suggests that it is a minority practice to even explicitly discuss data quality. I therefore suggest that this topic should become a higher priority amongst empirical software engineering researchers. © 2011 ACM."
"Villegas N.M., Müller H.A., Tamura G., Duchien L., Casallas R.",A framework for evaluating quality-driven self-adaptive software systems,2011,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959550156&doi=10.1145%2f1988008.1988020&partnerID=40&md5=87328f5539e05de7c67c753109f03509,"Over the past decade the dynamic capabilities of self-adaptive software-intensive systems have proliferated and improved significantly. To advance the field of self-adaptive and self-managing systems further and to leverage the benefits of self-adaptation, we need to develop methods and tools to assess and possibly certify adaptation properties of self-adaptive systems, not only at design time but also, and especially, at run-time. In this paper we propose a framework for evaluating quality-driven self-adaptive software systems. Our framework is based on a survey of self-adaptive system papers and a set of adaptation properties derived from control theory properties. We also establish a mapping between these properties and software quality attributes. Thus, corresponding software quality metrics can then be used to assess adaptation properties. © 2011 ACM."
"Savolainen J., Männistö T.",Conflict-centric software architectural views: Exposing trade-offs in quality requirements,2010,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958186171&doi=10.1109%2fMS.2010.139&partnerID=40&md5=9c5b83d4d132cc2a9bcd91093c9af365,"Much work on software architectures has focused on how to document them. This has improved the understanding of real-life architectures. However, when multiple stakeholder concerns need to be addressed, they easily become scattered throughout the documentation. One reason might be that architectural views typically don't support the easy evaluation of trade-offs between conflicting quality attributes. When these concerns and related architectural decisions are distributed among many views, they are less obvious to architects and stakeholders. The authors propose an approach to creating architectural views that more prominently communicate the conflicts between key stakeholders' concerns. The approach also tends to reduce the amount of architectural documentation and thus increase its communication value by highlighting architectural decisions made to resolve the conflicts identified. © 2006 IEEE."
"Humayun A., Basit W., Farrukh G.A., Lodhi F., Aden R.",An empirical analysis of team review approaches for teaching quality software development,2010,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954779749&doi=10.1145%2f1806799.1806882&partnerID=40&md5=59516307b4b52f172cd8b507790f6d71,"Reviews are an integral part of the software development process. They are one of the key methodologies that undergraduates study in order to develop quality software. Despite their importance, reviews are rarely used in software engineering projects at the baccalaureate level. This paper demonstrates results from a study conducted on students at baccalaureate level enrolled in a one-semester software engineering course at the National University of Computer and Emerging Sciences - Foundation for Advancement of Science and Technology (NUCES-FAST) in Pakistan. The objectives of the study are: to determine how the various team review techniques help to educate students about the importance of the review process and find which technique is more suitable for teaching reviews to undergraduates. Two variations on team review are proposed: Similar Domain Review (SDR) and Cross-Domain Review (CDR) without author. The paper presents a comparison of the proposed and existing team review techniques and measures their effectiveness in terms of defect detection. The results show that the proposed variation SDR is more effective in defect detection than CDR (with/without author). Another interesting result is that the proposed CDR-without author is better than CDR with author (the existing team review approach). Also, early defect detection enabled students to incorporate changes and improve the software quality. © 2010 ACM."
"Zheng J., Harper K.E.","Concurrency design patterns, software quality attributes and their tactics",2010,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954570582&doi=10.1145%2f1808954.1808964&partnerID=40&md5=46cfdf02f74de1d4d8809d601743a0e5,"With the prevalent application of multi-core CPUs, software practitioners are facing the challenge of developing high quality multi-threaded programs. Applying concurrency design patterns is one of the best practices in multi-core software engineering. We comprehensively surveyed 28 concurrency design patterns, and provided a problem-oriented guide that navigates software developers towards the ""right"" pattern(s) with minimal search/reading effort. The guide also illustrates the relationship between concurrency design patterns and the quality attributes they address. Additionally, further investigation was conducted on how these concurrency design patterns implement quality attributes tactics. We present a mapping between surveyed concurrency design patterns and the tactics for two important quality attributes: performance and modifiability. The results of these studies provide an insight into concurrency design patterns for software developers who are seeking appropriate or improved solutions to multi-threaded software development issues. © 2010 ACM."
"Bachmann A., Bernstein A.",When process data quality affects the number of bugs: Correlations in software engineering datasets,2010,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953774300&doi=10.1109%2fMSR.2010.5463286&partnerID=40&md5=8998845e532edbb8dc25941ad5697894,"Software engineering process information extracted from version control systems and bug tracking databases are widely used in empirical software engineering. In prior work, we showed that these data are plagued by quality deficiencies, which vary in its characteristics across projects. In addition, we showed that those deficiencies in the form of bias do impact the results of studies in empirical software engineering. While these findings affect software engineering researchers the impact on practitioners has not yet been substantiated. In this paper we, therefore, explore (i) if the process data quality and characteristics have an influence on the bug fixing process and (ii) if the process quality as measured by the process data has an influence on the product (i.e., software) quality. Specifically, we analyze six Open Source as well as two Closed Source projects and show that process data quality and characteristics have an impact on the bug fixing process: the high rate of empty commit messages in Eclipse, for example, correlates with the bug report quality. We also show that the product quality - measured by number of bugs reported - is affected by process data quality measures. These findings have the potential to prompt practitioners to increase the quality of their software process and its associated data quality. © 2010 IEEE."
"Trienekens J.J.M., Kusters R.J., Brussel D.C.","Quality specification and metrication, results from a case-study in a mission-critical software domain",2010,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956057048&doi=10.1007%2fs11219-010-9101-z&partnerID=40&md5=8676a4867b80d63fce5b0d10d732fb63,"Software quality is of increasing importance in mission-critical embedded software systems. Due to the fast growing complexity and accompanying risks of failures of these systems, software quality needs to be addressed explicitly by software developers, preferably with a systematic method for an optimal implementation of software qualities, such as reliability, time-behavior and usability. At the Centre of Automation of Mission-critical Systems (CAMS) of the Dutch Royal Navy, a new approach has been defined for software developers to improve the way that they deal with software quality in the process of mission-critical systems engineering. The stepwise approach is based on both an international quality standard for software product quality, i.e. ISO9126, and on Multi-Criteria Decision Making techniques, i.e. analytical hierarchy process (AHP). The stepwise approach has been validated in a case study. In particular, the tailoring of the ISO9126 standard toward the specific CAMS development situation, and the applicability of AHP techniques, from the perspective of software developers, has been investigated. The case study is carried out in a representative software development project, i.e. the software for combat management systems (CMS) of warships. Results of the case study show that software developers can explicitly deal with quality on the basis of both the ISO9126 standard and the AHP techniques, respectively regarding the specification, prioritization and metrication of software product quality. © 2010 The Author(s)."
"Sener Z., Karsak E.E.",A fuzzy regression and optimization approach for setting target levels in software quality function deployment,2010,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953480593&doi=10.1007%2fs11219-010-9095-6&partnerID=40&md5=90014463ba282d5a711f45572e77d3c0,"With the rapid development of the software industry, improving the quality of software development has gained increasing importance. Software manufacturers have recently applied quality improvement techniques to software development to respond to the needs for software quality. Software quality function deployment (SQFD), as a technique for improving the quality of the software development process to create products responsive to customer expectations, is used to maximize customer satisfaction. This paper presents a fuzzy regression and optimization approach to determine target levels in SQFD. The inherent fuzziness of relationships in SQFD modeling justifies the use of fuzzy regression. Fuzzy regression is used to identify the functional relationships between customer requirements and technical attributes, and among technical attributes. Then, a mathematical programming model is developed to determine target levels of technical attributes using the functional relationships obtained by fuzzy regression. A search engine quality improvement problem is presented to illustrate the application of the proposed approach. © 2010 Springer Science+Business Media, LLC."
Haigh M.,"Software quality, non-functional software requirements and IT-business alignment",2010,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953478255&doi=10.1007%2fs11219-010-9098-3&partnerID=40&md5=c282adcc1b14f37b160afdc5cae38f7d,"'High quality' might seem an obvious requirement for any piece of software, but do the different stakeholder groups involved in its production and use conceptualize this requirement in the same way? Many existing models refine the broad concept of quality into a number of well-defined and measurable attributes related to the software product itself and the development process which produced it. But despite growing awareness of the importance of achieving cultural alignment between holders of different business and IT groups, little attempt has been made to empirically examine the requirements for software quality held by different groups involved in the development process. We conducted a survey of more than 300 current and recently graduated students of one of the leading Executive MBA programs in the United States, asking them to rate the importance of each of 13 widely-cited attributes related to software quality. The results showed business role-related differences in some specific areas and agreement in many others. The results suggest that a strong shared culture may be able to bridge the gulf created between holders of IT and business stakeholder roles. © 2010 Springer Science+Business Media, LLC."
"Deissenboeck F., Juergens E., Lochmann K., Wagner S.","Software quality models: Purposes, usage scenarios and requirements",2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049485828&doi=10.1109%2fWOSQ.2009.5071551&partnerID=40&md5=8fcbe52cf221d20710deaf02231c9c19,"Software quality models are a well-accepted means to support quality management of software systems. Over the last 30 years, a multitude of quality models have been proposed and applied with varying degrees of success. Despite successes and standardisation efforts, quality models are still being criticised, as their application in practice exhibits various problems. To some extent, this criticism is caused by an unclear definition of what quality models are and which purposes they serve. Beyond this, there is a lack of explicitly stated requirements for quality models with respect to their intended mode of application. To remedy this, this paper describes purposes and usage scenarios of quality models and, based on the literature and experiences from the authors, collects critique of existing models. From this, general requirements for quality models are derived. The requirements can be used to support the evaluation of existing quality models for a given context or to guide further quality model development. © 2009 IEEE."
"Wong B., Bhatti M.",The influence of team relationships on software quality,2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049484277&doi=10.1109%2fWOSQ.2009.5071550&partnerID=40&md5=97a6101b529f8645b4d26d29dc2417b2,"Implementing software development successfully in an organization is possibly one of the most challenging issues that the industry faces today. Project failures and the lack of software quality have become a major concern for researchers and practitioners. For many software development projects as well as for many quality assurance departments, teamwork is extremely important. Therefore, nearly all organizations pay attention to teamwork which is essential for smooth operation of a project. It is believed that teamwork is crucial for the success or failure of a project. In addition to the importance of teamwork, team issues affecting its' performance also needs attention. Among these team issues, people issues are scarce in the literature. The research outlined in this paper investigated the factors which influence teamwork. It identified the importance of trust and how trust influences IT project teams and the role of project managers and team leaders in improving trust within teams. It also includes individual behaviors that affect trust within a team. A study of six project managers from two Australian organizations was conducted to investigate the factors which influence teamwork to result in project success and software quality. The results showed that trust is a central element of the many factors and that without trust in the team; teamwork will be negatively affected resulting in project failure and poor quality. © 2009 IEEE."
"Bombardieri M., Fontana F.A.",Software aging assessment through a specialization of the SQuaRE quality model,2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049458138&doi=10.1109%2fWOSQ.2009.5071554&partnerID=40&md5=3085a2d9022674d883b077f87722de88,"In the last years the software application portfolio has become a key asset for almost all companies. During their lives, applications undergo lots of changes to add new functionalities or to refactor older ones; these changes tend to reduce the quality of the applications themselves, causing the phenomenon known as software aging. Monitoring of software aging is very important for companies, but up to now there are no standard approaches to perform this task. In addition many of the suggested models assess software aging basing on few software features, whereas this phenomenon affects all of the software aspects. In 2005 ISO/IEC released the SQuaRE quality model which covers several elements of software quality assessment, but some issues make SQuaRE usage quite difficult. The purpose of this paper is to suggest an approach to software aging monitoring that considers the software product in its wholeness and to provide a specialization of the SQuaRE quality model which allows to perform this task. © 2009 IEEE."
"Salger F., Engels G., Hofmann A.",Inspection effectiveness for different quality attributes of software requirement specifications: An industrial case study,2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955167159&doi=10.1109%2fWOSQ.2009.5071552&partnerID=40&md5=6f5d87e6b9a0e8abe8256ba0756f9df0,"Early inspections of software requirements specifications (SRS) are known to be an effective and cost-efficient quality assurance technique. However, inspections are often applied with the underlying assumption that they work equally well to assess all kinds of quality attributes of SRS. Little work has yet been done to validate this assumption. At Capgemini sd&m, we set up an inspection technique to assess SRS, the so called ""specification quality gate"" (QG-Spec). The QG-Spec has been applied to a series of large scale commercial projects. In this paper we present our lessons learned and discuss, which quality attributes are effectively assessed by means of the QG-Spec - and which are not. We argue that our results can be generalized to other existing inspection techniques. We came to the conclusion that inspections have to be carefully balanced with techniques for constructive quality assurance in order to economically arrive at high quality SRS. © 2009 IEEE."
"Gousios G., Spinellis D.",Alitheia Core: An extensible software quality monitoring platform,2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949911315&doi=10.1109%2fICSE.2009.5070560&partnerID=40&md5=8f04e7f1a0aa62127f5fcda026a8e620,"Research in the fields of software quality and maintain-ability requires the analysis of large quantities of data, which often originate from open source software projects. Pre-processing data, calculating metrics, and synthesizing composite results from a large corpus of project artefacts is a tedious and error prone task lacking direct scientific value. The Alitheia Core tool is an extensible platform for software quality analysis that is designed specifically to facilitate software engineering research on large and diverse data sources, by integrating data collection and preprocessing phases with an array of analysis services, and presenting the researcher with an easy to use extension mechanism. The system has been used to process several projects successfully, forming the basis of an emerging ecosystem of quality analysis tools. © 2009 IEEE."
"Bird C., Nagappan N., Devanbu P., Gall H., Murphy B.",Does distributed development affect software quality? An empirical case study of windows vista,2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949887177&doi=10.1109%2fICSE.2009.5070550&partnerID=40&md5=b2268150b63c60366c76b7fa3a7dd644,"It is widely believed that distributed software development is riskier and more challenging than collocated development. Prior literature on distributed development in software engineering and other fields discuss various challenges, including cultural barriers, expertise transfer dif-ficulties, and communication and coordination overhead. We evaluate this conventional belief by examining the overall development of Windows Vista and comparing the postrelease failures of components that were developed in a distributed fashion with those that were developed by collocated teams. We found a negligible difference in failures. This difference becomes even less significant when controlling for the number of developers working on a binary. We also examine component characteristics such as code churn, complexity, dependency information, and test code coverage and find very little difference between distributed and collocated components to investigate if less complex components are more distributed. Further, we examine the software process and phenomena that occurred during the Vista development cycle and present ways in which the development process utilized may be insensitive to geography by mitigating the difficulties introduced in prior work in this area. © 2009 IEEE."
"Marri M.R., Thummalapenta S., Xie T.",Improving Software quality via code searching and mining,2009,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949788600&doi=10.1109%2fSUITE.2009.5070018&partnerID=40&md5=ad93b9e9acb8a8992d77216d08a24c2d,"Enormous amount of open source code is available on the Internet and various code search engines (CSE) are available to serve as a means for searching in open source code. However, usage of CSEs is often limited to simple tasks such as searching for relevant code examples. In this paper, we present a generic life-cycle model that can be used to improve software quality by exploiting CSEs. We present three example software development tasks that can be assisted by our life-cycle model and show how these three tasks can contribute to improve the software quality. We also show the application of our life-cycle model with a preliminary evaluation. © 2009 IEEE."
Tarvo A.,Mining software history to improve software maintenance quality: A case study,2009,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149512613&doi=10.1109%2fMS.2009.15&partnerID=40&md5=c43ea5eca7ea1dc04c0cf19037cdbb5e,"To keep the Windows operating system stable and secure, Microsoft constantly updates it. However, any update can cause a software regression - an undesired change in the system's stable parts. A key technique for fighting regressions is thorough testing of all updates, which is costly. A statistical model that estimates the risk for updates on the basis of their characteristics makes testing more efficient. Training this model requires collecting data on a large number of fixes made in previous versions of Windows. The Binary Change Tracer tool gets this information from the disparate data sources. © 2009 IEEE."
"Issa A.A., Abu Rub F.A., Thabata F.F.",Using test case patterns to estimate software development and quality management cost,2009,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650594947&doi=10.1007%2fs11219-009-9076-9&partnerID=40&md5=275e35298f34ea43b23576f2494bd244,"A novel process to discover test case patterns is proposed. This has led to the construction of a test case patterns catalogue. The catalogue has been analysed to estimate the potential reusability in different software applications. This has shown that 43% of system functions are generally application domain independent, whereas 57% are application domain dependent. Statistical tests showed that the level of specialisation in software systems could be as low as 20%, which supports the direction taken in this research to reuse test case patterns in software engineering activities, in particular, software cost estimation at the early sages of software development. © 2009 Springer Science+Business Media, LLC."
"Dos Santos R.P., De Oliveira K.M., Da Silva W.P.",Evaluating the service quality of software providers appraised in CMM/CMMI,2009,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650588099&doi=10.1007%2fs11219-008-9065-4&partnerID=40&md5=a0c3543209fa0aeadaf109b943e64e27,"Recently, several companies have decided to adopt maturity models such as the CMM/CMMI to ensure quality software processes. The state year report of the Software Engineering Institute (SEI) showed that more than three thousand CMMI appraisals have been conducted since 2002. Many of these were performed at software providers, i.e. companies that develop software for other companies. Although the costs of the implementation and appraisal of CMM/CMMI are high for the software providers, there is no formal study investigating whether this investment pays off or, in other words, whether their customers are measurably satisfied with the quality of the service provided. This article presents the results of a formal evaluation of customer perception of the service quality offered by the software providers appraised in CMM/CMMI. We developed an instrument based on a widely used service quality evaluation model (SERVQUAL) and applied this instrument to several customers of software providers appraised in CMM/CMMI. The results show a considerable discrepancy between customers' expectations and their perceptions of the services provided. © 2008 Springer Science+Business Media, LLC."
"Khoshgoftaar T.M., Rebours P., Seliya N.",Software quality analysis by combining multiple projects and learners,2009,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-65049088406&doi=10.1007%2fs11219-008-9058-3&partnerID=40&md5=06eba0a38d1ff8b43ab27b16cb75fa0e,"When building software quality models, the approach often consists of training data mining learners on a single fit dataset. Typically, this fit dataset contains software metrics collected during a past release of the software project that we want to predict the quality of. In order to improve the predictive accuracy of such quality models, it is common practice to combine the predictive results of multiple learners to take advantage of their respective biases. Although multi-learner classifiers have been proven to be successful in some cases, the improvement is not always significant because the information in the fit dataset sometimes can be insufficient. We present an innovative method to build software quality models using majority voting to combine the predictions of multiple learners induced on multiple training datasets. To our knowledge, no previous study in software quality has attempted to take advantage of multiple software project data repositories which are generally spread across the organization. In a large scale empirical study involving seven real-world datasets and seventeen learners, we show that, on average, combining the predictions of one learner trained on multiple datasets significantly improves the predictive performance compared to one learner induced on a single fit dataset. We also demonstrate empirically that combining multiple learners trained on a single training dataset does not significantly improve the average predictive accuracy compared to the use of a single learner induced on a single fit dataset. © 2008 Springer Science+Business Media, LLC."
Moses J.,Should we try to measure software quality attributes directly?,2009,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-64249172602&doi=10.1007%2fs11219-008-9071-6&partnerID=40&md5=0648b6d6e222796c2e98f7d73d843380,"Most external software quality attributes are conceptually subjective. For example, maintainability is an external software quality attribute, and it is subjective because interpersonally agreed definitions for the attribute include the phrase 'the ease with which maintenance tasks can be performed'. Subjectivity clearly makes measurement of the attributes and validation of prediction systems for the attributes problematic. In fact, in spite of the definitions, few statistically valid attempts at determining the predictive capability of prediction systems for external quality attributes have been published. When validations have been attempted, one approach used is to ask experts to indicate if the values provided by the prediction system informally agree with the experts' intuition. These attempts are undertaken without determining, independently of the prediction system, whether the experts are capable of direct consistent measurement of the attribute. Hence, a statistically valid and unbiased estimate of the predictive capability of the prediction system cannot be obtained (because the experts' measurement process is not independent of the prediction system's values). In this paper, it is argued that the problem of subjective measurement of quality attributes should not be ignored if quality is to be introduced into software in a controlled way. Further, it is argued that direct measurement of quality attributes should be encouraged and that in fact such measurement can be quantified to establish consistency using an existing approach. However, the approach needs to be made more accessible to promote its use. In so doing, it would be possible to decide whether consistent independent estimates of the true values of software quality attributes can be assigned and prediction systems for quality attributes developed. © 2009 Springer Science+Business Media, LLC."
"Paech B., Wetter T.",Rational quality requirements for medical software,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349160287&doi=10.1145%2f1368088.1368176&partnerID=40&md5=ee7159688c9ff44dfeee64f309aa9661,In this paper we discuss the challenges of software quality for medical software and present some ideas for improving medical software quality requirements through software engineering methods. We apply the quality requirements engineering method MOQARE to elicit specific quality requirements for an imaginary drug advisory system and report our lessons learned. Copyright 2008 ACM.
"Bakota T., Beszédes A., Ferenc R., Gyimóthy T.",Continuous software quality supervision using source inventory and columbus,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349138856&doi=10.1145%2f1370175.1370193&partnerID=40&md5=da38b72dde1093c2ee7dba33829c5806,"Several tools and methods for source code quality assurance based on static analysis finally reached a state when they are applicable in practice and recognized by the industry. However, most of these tools are used in an isolated manner and very rarely as organic parts of the quality assurance process. Furthermore, little or no help is provided in interpreting the outputs of these tools. This paper presents Source Inventory, a system for source code-based software quality assessment and monitoring, which is able to collect, store and present measurement data including metrics, coding problems and other kinds of data like bug numbers and test coverage information. It helps software developers, architects and managers to take control over their software's quality by performing continuous code scans, fault detection, coding style verification, architecture violation detection, and automatic report generation considering metric baselines."
"Nagappan N., Murphy B., Basili V.R.",The influence of organizational structure on software quality: An empirical case study,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57049120016&doi=10.1145%2f1368088.1368160&partnerID=40&md5=19360123674f7d87fc739220624c0ad1,"Often software systems are developed by organizations consisting of many teams of individuals working together. Brooks states in the Mythical Man Month book that product quality is strongly affected by organization structure. Unfortunately there has been little empirical evidence to date to substantiate this assertion. In this paper we present a metric scheme to quantify organizational complexity, in relation to the product development process to identify if the metrics impact failure-proneness. In our case study, the organizational metrics when applied to data from Windows Vista were statistically significant predictors of failure-proneness. The precision and recall measures for identifying failure-prone binaries, using the organizational metrics, was significantly higher than using traditional metrics like churn, complexity, coverage, dependencies, and pre-release bug measures that have been used to date to predict failure-proneness. Our results provide empirical evidence that the organizational metrics are related to, and are effective predictors of failure-proneness. Copyright 2008 ACM."
"Rana Z.A., Shamail S., Awais M.M.",Towards a generic model for software quality prediction,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57149116564&doi=10.1145%2f1370099.1370108&partnerID=40&md5=a9ab5cf643251f0801b615aacac6c9e5,"Various models and techniques have been proposed and applied in literature for software quality prediction. Specificity of each suggested model is one of the impediments in development of a generic model. A few models have been quality factor specific whereas others are software development paradigm specific. The models can even be company specific or domain specific. The amount of work done for software quality prediction compels the researchers to get benefit from the existing models and develop a relatively generic model. Development of a generic model will facilitate the quality managers by letting them focus on how to improve the quality instead of employing time on deciding which technique best suites their scenario. This paper suggests a generic model which takes software as input and predicts a quality factor value using existing models. This approach captures the specificity of existing models in various dimensions (like quality factor, software development paradigm, and software development life cycle phase etc.), and calculates quality factor value based on the model with higher accuracy. Application of the model has been discussed with the help of an example. Copyright 2008 ACM."
Verner J.M.,Quality software development: What do we need to improve in the software development process?,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57049187241&doi=10.1145%2f1370099.1370100&partnerID=40&md5=1bfb947e48d001fb3000933de021ef29,"There are a number of authors who have documented problems with our software development processes. Unrealistic schedules and budgets, with continuing steams of requirements changes lead to projects with a high risk of failure. There is too often only a vague idea of the required solution at the outset of a project and this makes it difficult for estimators and developers. It is commonly accepted that there will be requirements changes throughout the project. This means that managing changes becomes a challenge. Most IT experts agree that failures occur far more often than they should. Most developments are expensive, with a difficult process affected by a series of problems including poor project management, cost and schedule overruns, poor quality software and under-motivated developers. Unfortunately few project post-mortems are conducted, and little understanding is gained from the results of past projects Most project failures are predictable and avoidable, but many project managers cannot identify what success and failure factors are important, early enough to take action. Many factors are described in the literature including project pressures with project stakeholders impacting the cost and quality of the project, organizational structure, communication with customer/users, and amongst customers, developers & users, stakeholder politics, commercial pressures, poor leadership, lack of upper management support and personality conflicts, unrealistic, unarticulated goals, poor user requirements and requirements specification, customer satisfaction; scheduling, project budget, and inaccurate estimates of resources, poor project management, poor reporting of project status, unmanaged risks, inability to handle project complexity, the project management process and tracking tools, sloppy development practices, software development methodologies, use of immature technology, product quality, business processes and resources. There are generally more than 1 or 2 reasons for a project failure which may be caused by a combination of technical, project management and business decisions. Most organizations do not see preventing failure as an urgent matter. Unfortunately, the literature on project failure is based on handful of failed project case studies. Our research is concerned with getting quantitative evidence on aspects contributing to failure. If we know what factors are responsible for failure we can focus on these factors and improve the quality of our development processes for future projects. We also should recognize effects of project failure on development staff. Late projects usually cause long hours of unpaid overtime, loss of motivation, and stress. This then leads to high staff turnover and its associated costs. This research provides an update on prior studies and tests the validity of previously reported anecdotal evidence about project failure factors. We build on previously reported research but our concern is with everyday projects, not the high profile projects normally reported in the newspapers. We collected a set of project data and teased it out to find the main failure factors for a whole group of projects. We first developed a questionnaire targeting software developers' perceptions of practices affecting project outcomes. Our questionnaire was based on extensive discussions with 90+ software developers as well as the literature. The survey included 88 questions organized into sections covering sponsor/senior management, customer/user, requirements, estimation and scheduling, the development process, the project manager and project management, and the development team. We also asked if the project was a success or a failure. The questionnaire was distributed to practitioners from a large U.S. financial institution where each responded by answering it twice. It was then distributed to various companies in North Eastern U.S.A., a number of different Australian companies; and a number of different Chilean organizations; each respondent in the latter groups answered the questionnaire once. We collected data on 304 projects, 70 were failures. Of the failed projects, 49 were in-house and 21 outsourced, 65 were development projects and 5 maintenance projects. The largest project that failed had 180 developers. We examined the data using frequency analyses and as well investigated relationships between the most important factors."
"Liebchen G.A., Shepperd M.",Data sets and data quality in software engineering,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57049148158&doi=10.1145%2f1370788.1370799&partnerID=40&md5=21ccb9b70d37e6fc5ca9f6c5aeec640b,"OBJECTIVE - to assess the extent and types of techniques used to manage quality within software engineering data sets. We consider this a particularly interesting question in the context of initiatives to promote sharing and secondary analysis of data sets. METHOD - we perform a systematic review of available empirical software engineering studies. RESULTS - only 23 out of the many hundreds of studies assessed, explicitly considered data quality. CONCLUSIONS - first, the community needs to consider the quality and appropriateness of the data set being utilised; not all data sets are equal. Second, we need more research into means of identifying, and ideally repairing, noisy cases. Third, it should become routine to use sensitivity analysis to assess conclusion stability with respect to the assumptions that must be made concerning noise levels. Copyright 2008 ACM."
"Salvaneschi P., Piazzalunga U.",Engineering models and software quality models: An example and a discussion,2008,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959190479&doi=10.1145%2f1370731.1370741&partnerID=40&md5=d2ce735f0f93bb485210c6ccb9125006,"The paper compares the models used for software quality evaluation to the modelling approach of other engineering fields. The conclusion is that, while large efforts have been devoted to the definition of measurable attributes and related measures, product models specifically developed for measuring quality characteristics are until now not sufficiently explored. We explore the concept of ""quality-oriented specialized product models"" and we claim that this is an important ingredient for an engineering approach to the software quality measurement. We describe an example of this type of models for measuring the security of a specific type of copy protection mechanisms. The model forecasts the amount of time a hypothetical attacker would need to break the protection. Copyright 2008 ACM."
"Blaine J.D., Cleland-Huang J.",Software quality requirements: How to balance competing priorities,2008,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-40949089293&doi=10.1109%2fMS.2008.46&partnerID=40&md5=92cff91e274c9915234437f2b7b9e83e,"The elicitation, analysis, and specification of quality requirements involve careful balancing of a broad spectrum of competing priorities. Developers must therefore focus on identifying qualities and designing solutions that optimize the product's value to its stakeholders. © 2008 IEEE."
"Chang C.-W., Wu C.-R., Lin H.-L.",Integrating fuzzy theory and hierarchy concepts to evaluate software quality,2008,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149193088&doi=10.1007%2fs11219-007-9035-2&partnerID=40&md5=c0726b7b8745845e0160bf4ff0966f32,"This study proposes a software quality evaluation model and its computing algorithm. Existing software quality evaluation models examine multiple characteristics and are characterized by factorial fuzziness. The relevant criteria of this model are derived from the international norm ISO. The main objective of this paper is to propose a novel Analytic Hierarchy Process (AHP) approach for addressing uncertainty and imprecision in service evaluation during pre-negotiation stages, where comparative judgments of decision makers are represented as fuzzy triangular numbers. A new fuzzy prioritization method, which derives crisp priorities from consistent and inconsistent fuzzy comparison matrices, is proposed. The Fuzzy Analytic Hierarchy Process (FAHP)-based decision-making method can provide decision makers or buyers with a valuable guideline for evaluating software quality. Importantly, the proposed model can aids users and developers in assessing software quality, making it highly applicable for academic and commercial purposes. © 2007 Springer Science+Business Media, LLC."
"Plösch R., Gruber H., Hentschel A., Körner Ch., Pomberger G., Schiffer S., Saft M., Storck S.",The EMISQ method - Expert based evaluation of internal software quality,2007,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-47749132628&doi=10.1109%2fSEW.2007.71&partnerID=40&md5=cd7975c8b3e6f9fec2a175545c539b15,"Internal software quality, e.g. the quality of code, has great impact on the overall quality of software. Besides well known manual inspection and review techniques more recent approaches utilize tool-based static code for the evaluation of internal software quality. Despite the high potential of static code analyzers the application of tools alone cannot replace well founded expert opinion. Knowledge, experience and fair judgement is indispensable for a valid, reliable quality assessment, which is accepted by software developers and managers. The EMISQ method (Evaluation Method for Internal Software Quality), guides the assessment process for all stakeholders of an evaluation project. The method is supported by a tool that assists evaluators with their analysis and rating tasks and provides support for generating a code quality report. The application of the method in a pilot project has shown its applicability."
"Côté M.-A., Suryn W., Georgiadou E.",In search for a widely applicable and accepted software quality model for software quality engineering,2007,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-36549049028&doi=10.1007%2fs11219-007-9029-0&partnerID=40&md5=59c39869ee11beea4f39ae055a8804c0,"Software Quality Engineering is an emerging discipline that is concerned with improving the approach to software quality. It is important that this discipline be firmly rooted in a quality model satisfying its needs. In order to define the needs of this discipline, the meaning of quality is broadly defined by reviewing the literature on the subject. Software Quality Engineering needs a quality model that is usable throughout the software lifecycle and that it embraces all the perspectives of quality. The goal of this paper is to propose the characteristics of a quality model suitable for such a purpose, through the comparative evaluation of existing quality models and their respective support for Software Quality Engineering. © 2007 Springer Science+Business Media, LLC."
"Elliott M., Dawson R., Edwards J.",An analysis of software quality management at AWE plc.,2007,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-36549027018&doi=10.1007%2fs11219-007-9027-2&partnerID=40&md5=fc0cba2f7f72e75b8bc9dec833b08d8b,"A detailed question set is required to test and measure the true extent that a software quality management system is adopted and implemented across a large company like Atomic Weapons Establishment (AWE) plc. The analysis of the gathered data reveals specific topics of weakness that can also reflect the cultural acceptance or resistance that management groups have towards the adoption of quality systems. Having identified detailed problems and barriers, effective strategies and programmes can be deployed to improve the level of implementation and, therefore, the effectiveness of a software quality management system. This paper presents the question set used and the subsequent results obtained from the implementation assessment for 55 software systems at AWE plc. The data is collated into management groups and the associated cultures discussed. The topics of weakness are highlighted together with the very specific actions that are least undertaken. A range of improvement actions is also presented. © 2007 Springer Science+Business Media, LLC."
Aberdour M.,Achieving quality in open-source software,2007,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846917203&doi=10.1109%2fMS.2007.2&partnerID=40&md5=08d47741430e05c8a0ceb015a1f43a04,"The open source software community has published a substantial body of research on OSS quality. Focusing on this peer-reviewed body of work lets us draw conclusions from empirical data rather than rely on the large volume of evangelical opinion that has historically dominated this field. This body of published research has become much more critical and objective in its efforts to understand OSS development, and a consensus has emerged on the key components of high-quality OSS delivery. This article reviews this body of research and draws out lessons learned, investigating how the approaches used to deliver high-quality OSS differ from, and can be incorporated into, closed-source software development. © 2007 IEEE."
"Damm L.-O., Lundberg L.",Using fault slippage measurement for monitoring software process quality during development,2006,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885655995&doi=10.1145%2f1137702.1137707&partnerID=40&md5=a72e3ef2602755e39c97e34a92a563e9,"In a competitive environment where time-to-market is crucial for success, software development companies initiate process improvement programs that can shorten the development time. They especially seek improvements in the verification activities since rework commonly constitutes a significant part of the development cost. However, the success of process improvement initiatives is dependent on early and observable results since a lack of feedback on the effect of improvements is a common cause of failure. This paper investigates how to monitor the verification process as input to decisions such as improvement actions. The suggested approach was applied on three industrial software products at Ericsson and the results determined that the approach can be used for quantitative monitoring of process quality and as decision support to do rapid improvement actions. © 2006 ACM."
"Washizaki H., Kobayashi Y., Watanabe H.",Experiments on quality evaluation of embedded software in Japan robot software design contest,2006,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247114304&partnerID=40&md5=f38f8d7a84c99a1f2ee51e8639582d1c,"As a practical opportunity for educating Japanese young developers in the field of embedded software development, a software design contest involving the design of software to automatically control a line-trace robot, and conduct running performance tests was held. In this paper, we give the results of the contest from the viewpoint of software quality evaluation. We create a framework for evaluating the software quality which integrated design model quality and the final system performance, and conduct analysis using the framework. As a result of analysis, it is found that the quantitative measurement of the structural complexity of the design models bears a strong relationship to qualitative evaluation of the design conducted by judges. It is also found that there is no strong correlation between design model quality evaluated by the judges and the final system performance. For embedded software development, it is particularly important to estimate and verify reliability and performance in the early stages, using the model. Based on the analysis result, we consider possible remedies with respect to the models submitted, the evaluation methods used and the contest specifications. In order to adequately measure several non-functional quality characteristics including performance on the model, it is necessary to improve the way of developing robot software (such as applying model driven development) and reexamine the evaluation methods. Copyright 2006 ACM."
Crispin L.,Driving software quality: How test-driven development impacts software quality,2006,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846907119&doi=10.1109%2fMS.2006.157&partnerID=40&md5=1c6ac14fdd83073f861f9ec5b1e95701,"Recently, software development teams using agile processes have started widely adopting test-driven development. But does TDD really improve software quality? © 2006 IEEE."
"Issac G., Rajendran C., Anantharaman R.N.",An instrument for the measurement of customer perceptions of quality management in the software industry: An empirical study in India,2006,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749595095&doi=10.1007%2fs11219-006-0037-2&partnerID=40&md5=ef13c6f2124ac39949bd868ebb09a2e0,"Most of the available literature on quality management is based on management's perception; few studies examine critical issues of quality management from the customer's perspective, especially in the software industry. In order to gain an insight into what customers expect from a product/service, an analysis of quality management from customer's point of view is essential. Such an understanding would help the managers to adopt strategies that can enhance the satisfaction level of their customers. The present study highlights the critical factors of quality management in the software industry from the customer's perspective. Six critical factors are identified: and an instrument, comprising these factors, is developed and validated so as to measure the customer's perception of quality management in the software industry. © Springer Science + Business Media, LLC 2006."
"Liu F., Noguchi K., Dhungana A., Srirangam A. V.V.N.S.N., Inuganti P.",A quantitative approach for setting technical targets based on impact analysis in software quality function deployment (SQFD),2006,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746875209&doi=10.1007%2fs11219-006-7598-y&partnerID=40&md5=6eecb6909b62121f64d43e6f2daed4c7,"Target setting in software quality function deployment (SQFD) is very important since it is directly related to development of high quality products with high customer satisfaction. However target setting is usually done subjectively in practice, which is not scientific. Two quantitative approaches for setting target values: benchmarking and primitive linear regression have been developed and applied in the past to overcome this problem (Akao and Yoji, 1990). But these approaches cannot be used to assess the impact of unachieved targets on satisfaction of customers for customer requirements. In addition, both of them are based on linear regression and not very practical in many applications. In this paper, we present an innovative quantitative method of setting technical targets in SQFD to enable analysis of impact of unachieved target values on customer satisfaction. It is based on assessment of impact of technical attributes on satisfaction of customer requirements. In addition both linear and non linear regression techniques are utilized in our method, which certainly improves the existing quantitative methods which are based on only linear regression. © Springer Science + Business Media, Inc. 2006."
"Saunders S., Ross M., Staples G., Wellington S.",The software quality challenges of service oriented architectures in e-commerce,2006,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33244469280&doi=10.1007%2fs11219-006-6002-2&partnerID=40&md5=4a75561cafd69887db2378a084af2ed1,"Web Services technologies and their supporting collection of de facto standards are now reaching the point of maturity where they are appearing in production software systems. Service Oriented Architectures (SOAs) using Web Services as an enabling technology are also being discussed widely in the IT press. However, despite the numerous and real advantages of these architectural patterns there are still many software quality challenges that remain unresolved. This is particularly true as we consider more advanced architectures that exploit the technology to its maximum advantage: utility computing and on-demand service discovery and composition, grid computing and multi-agent systems will only become pervasive once the software quality challenges of real-world industrial applications have been addressed. In this paper potential quality issues such as performance, reliability and availability are addressed in terms of the quality assurances that might need to be provided to consumers of services. Proposed XML-based Service Level Agreement (SLA) languages are reviewed as a means of providing these quality assurances in machine-readable ways. We also discuss how SLAs might be automatically negotiated to enable automated, on-demand service discovery and composition. The next section of this paper addresses quality issues from a service provider's perspective. The providers of such services will need to ensure that SLA commitments are met and this poses interesting problems in terms of application management. Network quality of service is currently addressed through such means as IntServ and DiffServ. Research proposals to introduce similar techniques at an application level are described. From the service consumer's perspective, interesting research proposals for proactively ensuring that good quality of service is obtained are also reviewed. These could be particularly important for creating confidence, from a consumer's perspective, in these architectures. Finally, the paper evaluates the challenges and suggests areas where further research is most urgently required. © Springer Science + Business Media, Inc. 2006."
"Zuser W., Heil S., Grechenig T.","Software quality development and assurance in RUP, MSF and XP -A comparative study",2005,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885903144&doi=10.1145%2f1083292.1083300&partnerID=40&md5=c47fec6c93dd2cc890ba61b5ce2ab7c1,"The support of software quality in a software development process may be regarded under two aspects: first, by providing techniques, which support the development of high quality software and second, by providing techniques, which assure the required quality attributes in existing artifacts. Both approaches have to be combined to achieve effective and successful software engineering. In this study, we compare three of the most industrially relevant software development process models (Rational Unified Process (RUP), Microsoft Solution Framework (MSF) and Extreme Programming (XP)) regarding their software quality support in terms of software quality development and software quality assurance. Based on the results we propose a de-facto standard for quality support in software development process models. © 2005 ACM."
"Nagappan N., Williams L., Vouk M., Osborne J.",Early estimation of software quality using in-process testing metrics: A controlled case study,2005,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955433687&doi=10.1145%2f1083292.1083304&partnerID=40&md5=c3b21a87b407b65539153ab3017b0eda,"In industrial practice, information on post-release field quality of a product tends to become available too late in the software development process to affordably guide corrective actions. An important step towards remediation of this problem of late information lies in the ability to provide an early estimation of software post-release field quality. This paper presents the use of a suite of in-process metrics that leverages the software testing effort to provide (1) an estimation of potential software field quality in early software development phases, and (2) the identification of low quality software programs. A controlled case study conducted at North Carolina State University provides initial indication that our approach is effective for making an early assessment of post-release field quality. © 2005 ACM."
"Dahlgren T.L., Devanbu P.T.",Improving scientific software component quality through assertions,2005,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954433188&doi=10.1145%2f1145319.1145341&partnerID=40&md5=3e2d8e96ab9ab9d7e44210eba3b18e87,"We are proposing research on self-adaptive interface assertion enforcement for the purposes of improving scientific software component quality. Demonstrating software correctness through assertions is a well-known technique for quality improvement. However, the performance penalty is often considered too high for deployment. In order to determine if partial enforcement based on adaptive sampling is a viable solution in performance critical environments, we are pursuing research on mechanisms combining static and dynamic analyses to efficiently maximize assertion checking within performance constraints. This paper gives an overview of our initial experiments, current work, and plans. Copyright 2005 ACM."
"Ai-Naeem T., Gorton I., Babar M.A., Rabhi F., Benatallah B.",A quality-driven systematic approach for architecting distributed software applications,2005,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27844611786&doi=10.1109%2fICSE.2005.1553567&partnerID=40&md5=d9d66cc9571f050d6c26a07b5da85575,"Architecting distributed software applications is a complex design activity. It involves making decisions about a number of inter-dependent design choices that relate to a range of design concerns. Each decision requires selecting among a number of alternatives; each of which impacts differently on various quality attributes. Additionally, there are usually a number of stakeholders participating in the decision-making process with different, often conflicting, quality goals, and project constraints, such as cost and schedule. To facilitate the architectural design process, we propose a quantitative quality-driven approach that attempts to find the best possible fit between conflicting stakeholders' quality goals, competing architectural concerns, and project constraints. The approach uses optimization techniques to recommend the optimal candidate architecture. Applicability of the proposed approach is assessed using a real system. Copyright 2005 ACM."
"Hayes J.H., Dekhtyar A., Sundaram S.K.",Improving after-the-fact tracing and mapping: Supporting software quality predictions,2005,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-28244483794&doi=10.1109%2fMS.2005.156&partnerID=40&md5=6f24ea0c002df6aa604fe6e755d947a6,"The requirements traceability matrix can successfully predict quality before code is written. However, its tedious development process, requiring analysts to manually discover and vet links between artifact levels, has stymied widespread adoption. The authors' tracing toolkit, called Retro (Requirements Tracing on Target), automates the information retrieval process, making RTM's development easier. Backed by empirical results, the authors describe Retro's advantages over other information retrieval approaches. © 2005 IEEE."
"Khoshgoftaar T.M., Seliya N., Gao K.",Assessment of a new three-group software quality classification technique: An empirical case study,2005,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-17444406700&doi=10.1007%2fs10664-004-6191-x&partnerID=40&md5=bfb565d9885eb916cf2e87505de6380f,"An innovation method that circumvents the complexities, computational overhead, and difficulties involved in calibrating pure or direct three-group classification models was presented. Practioners can utilize an existing two-group classification algorithm thrice in order to yield the three risk-based classes with the application of the proposed method. An empirical approach was taken to investigate the effectiveness and validity of the proposed methodology. It was observed that the expected cost of miscalculation of the proposed three-group models were significantly better when compared to the technique's direct three-group model."
"Amasaki S., Yoshitomi T., Mizuno O., Takagi Y., Kikuno T.",A new challenge for applying time series metrics data to software quality estimation,2005,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-18244398924&doi=10.1007%2fs11219-005-6216-8&partnerID=40&md5=7d8a24827413547c00fbf8fd55b95279,"In typical software development, a software reliability growth model (SRGM) is applied in each testing activity to determine the time to finish the testing. However, there are some cases in which the SRGM does not work correctly. That is, the SRGM sometimes mistakes quality for poor quality products. In order to tackle this problem, we focussed on the trend of time series data of software defects among successive testing phases and tried to estimate software quality using the trend. First, we investigate the characteristics of the time series data on the detected faults by observing the change of the number of detected faults. Using the rank correlation coefficient, the data are classified into four kinds of trends. Next, with the intention of estimating software quality, we investigate the relationship between the trends of the time series data and software quality. Here, software quality is defined by the number of faults detected during six months after shipment. Finally, we find a relationship between the trends and metrics data collected in the software design phase. Using logistic regression, we statistically show that two review metrics in the design and coding phase can determine the trend. © 2005 Springer Science + Business Media, Inc."
"Côté M.-A., Suryn W., Laporte C.Y., Martin R.A.",The evolution path for industrial software quality evaluation methods applying ISO/IEC 9126:2001 quality model: Example of MITRE's SQAE method,2005,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-17444388547&doi=10.1007%2fs11219-004-5259-6&partnerID=40&md5=09ec05c221610b4c799ab6111def6568,"This paper examines how the industrial applicability of both ISO/IEC 9126:2001 and MITRE Corporation's Software Quality Assessment Exercise (SQAE) can be bolstered by migrating SQAE's quality model to ISO/IEC 9126:2001. The migration of the quality model is accomplished through the definition of an abstraction layer. The consolidated quality model is examined and further improvements to enrich the assessment of quality are enumerated. © 2005 Springer Science + Business Media, Inc."
Mäntylä M.V.,Developing new approaches for software design quality improvement based on subjective evaluations,2004,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4544373235&partnerID=40&md5=aeec638bf82ac49e0dcf3c4a916872b9,This research abstract presents two approaches for utilizing the developers' subjective design quality evaluations during the software lifecycle. In process-based approach developers study and improve their system's structure at fixed intervals. Tool-based approach uses subjective evaluations as input to tool analysis. These approaches or their combination are expected to improve software design and promote organizational learning about software design.
"Jung H.-W., Kim S.-O., Chung C.-S.",Measuring software product quality: A survey of ISO/IEC 9126,2004,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4644328140&doi=10.1109%2fMS.2004.1331309&partnerID=40&md5=806cc089be00baf45f49985bf0cd1cdd,"A user survey was carried out to evaluate empirically ISO/IEC 9126's dimensionality, or the classification of characteristics, and internal- consistency reliability. In the survey, users evaluated their satisfaction concerning the quality of a packaged software product according to the criteria of ISO/IEC 9126's subcharacteristics. Overall, results reveal ambiguities in the way that ISO/IEC 9126 is structured in terms of characteristics and subcharacteristics."
"Berki E., Georgiadou E., Holcombe M.",Requirements engineering and process modelling in software quality management - Towards a generic process metamodel,2004,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142676780&doi=10.1023%2fB%3aSQJO.0000034711.87241.f0&partnerID=40&md5=57a51d22bc656cff90603f0d24ae4251,"This paper examines the concept of Quality in Software Engineering, its different contexts and its different meanings to various people. It begins with a commentary on quality issues for systems development and various stakeholders' involvement. It revisits aspects and concepts of systems development methods and highlights the relevance of quality issues to the choice of a process model. A summarised review of some families of methods is presented, where their application domain, lifecycle coverage, strengths and weaknesses are considered. Under the new development era the requirements of software development change; the role of methods and stakeholders change, too. The paper refers to the latest developments in the area of software engineering and emphasises the shift from traditional conceptual modelling to requirements engineering and process metamodelling principles. We provide support for an emerging discipline in the form of a software process metamodel to cover new issues for software quality and process improvement. The widening of the horizons of software engineering both as a 'communication tool' and as a 'scientific discipline' (and not as a 'craft') is needed in order to support both communicative and scientific quality systems properties. In general, we can consider such a discipline as a thinking tool for understanding the generic process and as the origin of combining intuition and quality engineering to transform requirements to adequate human-centred information systems. We conclude with a schematic representation of a Generic Process Metamodel (GPM) indicating facets contributed by Software Engineering, Computer Science, Information Systems, Mathematics, Linguistics, Sociology and Anthropology. Ongoing research and development issues have provided evidence for influence from even more diverse disciplines."
"Eickelmann N., Hayes J.H.",New Year's Resolutions for Software Quality,2004,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0742321099&doi=10.1109%2fMS.2004.1259165&partnerID=40&md5=08f115ebac6c5ed6aef53692c3b445eb,"The views of various individuals on improvement of software quality are presented. Victor R.Basili stated that software organizations should observe and analyze their software development processes and products. One of the creators of software reliability engineering expressed that these organizations must recognize that users view product quality as the trade-off among reliability, time of delivery and cost that best needs, given the way in which they expect to use the product. Some of the researchers recognized that testing software is as important as writing."
"Khoshgoftaar T.M., Seliya N.",Analogy-Based Practical Classification Rules for Software Quality Estimation,2003,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0141924286&doi=10.1023%2fA%3a1025316301168&partnerID=40&md5=c55c23db4d307f95d3a30705f91b2729,"Software metrics-based quality estimation models can be effective tools for identifying which modules are likely to be fault-prone or not fault-prone. The use of such models prior to system deployment can considerably reduce the likelihood of faults discovered during operations, hence improving system reliability. A software quality classification model is calibrated using metrics from a past release or similar project, and is then applied to modules currently under development. Subsequently, a timely prediction of which modules are likely to have faults can be obtained. However, software quality classification models used in practice may not provide a useful balance between the two misclassification rates, especially when there are very few faulty modules in the system being modeled. This paper presents, in the context of case-based reasoning, two practical classification rules that allow appropriate emphasis on each type of misclassification as per the project requirements. The suggested techniques are especially useful for high-assurance systems where faulty modules are rare. The proposed generalized classification methods emphasize on the costs of misclassifications, and the unbalanced distribution of the faulty program modules. We illustrate the proposed techniques with a case study that consists of software measurements and fault data collected over multiple releases of a large-scale legacy telecommunication system. In addition to investigating the two classification methods, a brief relative comparison of the techniques is also presented. It is indicated that the level of classification accuracy and model-robustness observed for the case study would be beneficial in achieving high software reliability of its subsequent system releases. Similar observations are made from our empirical studies with other case studies."
"MacCormack A., Kemerer C.F., Cusumano M., Crandall B.",Trade-offs between productivity and quality in selecting software development practices,2003,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0141502244&doi=10.1109%2fMS.2003.1231158&partnerID=40&md5=aba6974e2c7b9358f2447dd164332285,"Choosing appropriate practices for a project can be hard, given the various dimensions of performance each claims to optimize. Using data from 29 projects, the impact of eight development practices on both productivity and quality was examined. The overall results showed that at the beginning of each project, practitioners should establish the primary performance objectives for the software deliverable, given that these will largely drive the type of development model and mix of practices they should use."
"Khoshgoftaar T.M., Seliya N.",Fault prediction modeling for software quality estimation: Comparing commonly used techniques,2003,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042767590&doi=10.1023%2fA%3a1024424811345&partnerID=40&md5=4f15d83ee9b1408272d2b79e7a2ea851,"High-assurance and complex mission-critical software systems are heavily dependent on reliability of their underlying software applications. An early software fault prediction is a proven technique in achieving high software reliability. Prediction models based on software metrics can predict number of faults in software modules. Timely predictions of such models can be used to direct cost-effective quality enhancement efforts to modules that are likely to have a high number of faults. We evaluate the predictive performance of six commonly used fault prediction techniques: CART-LS (least squares), CART-LAD (least absolute deviation), S-PLUS, multiple linear regression, artificial neural networks, and case-based reasoning. The case study consists of software metrics collected over four releases of a very large telecommunications system. Performance metrics, average absolute and average relative errors, are utilized to gauge the accuracy of different prediction models. Models were built using both, original software metrics (RAW) and their principle components (PCA). Two-way ANOVA randomized-complete block design models with two blocking variables are designed with average absolute and average relative errors as response variables. System release and the model type (RAW or PCA) form the blocking variables and the prediction technique is treated as a factor. Using multiple-pairwise comparisons, the performance order of prediction models is determined. We observe that for both average absolute and average relative errors, the CART-LAD model performs the best while the S-PLUS model is ranked sixth."
Georgiadou E.,"GEQUAMO - A generic, multilayered, customisable, software quality model",2003,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3543133647&doi=10.1023%2fA%3a1025817312035&partnerID=40&md5=badb2f8c8a55653a96fec05d28815c48,"Software quality models have primarily been based on top down process improvement approaches. Such models are based on the fundamental principle of empowerment of all involved and foster a questioning attitude through the active exchange of ideas and criticism ensuring that the most appropriate approach for quality improvements is adopted. The holistic view of systems enables the incorporation of many viewpoints held by different parties within the same organisation and by the same party at different stages of development. In this paper the GEQUAMO (GEneric, multilayered and customisable) QUAlity MOdel is proposed. GEQUAMO encapsulates the requirements of different stakeholders in a dynamic and flexible manner so as to enable each stakeholder (developer, user or sponsor) to construct their own model reflecting the emphasis/weighting for each attribute/requirement. Using a combination of the CFD (Composite Features Diagramming Technique) developed by the author, and Kiviat diagrams a multilayered and dynamic model is constructed. Instances of models are presented together with the algorithm for the computation of the profiles. Indications of future work conclude the paper."
"Ortega M., Pérez M., Rojas T.",Construction of a systemic quality model for evaluating a software product,2003,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3543054780&doi=10.1023%2fA%3a1025166710988&partnerID=40&md5=f6915840807fb5204c5c331644d47524,"Quality is currently considered one of the main assets with which a firm can enhance its competitive global position. This is one reason why quality has become essential for ensuring that a company's products and processes meet customers' needs. A recent innovation in the systems area is the development of a set of mechanisms and models for evaluating quality. This article describes the design of a Quality Model with a systemic approach to software products that assesses a product's efficiency and effectiveness. Different quality models were studied: McCall, Boehm, FURPS, ISO 9126, Dromey, ISO 15504 in an attempt to identify the aspects present in these models that are deemed important in a Systemic Quality model. We designed a model prototype that reflects the essential attributes of quality. This model was evaluated using a method so it can be validated and also enhanced. The evaluation method consisted of: designing a survey, formulating, validating and applying the measurement instruments; defining an algorithm to obtain the quality estimate and analyzing the results. The model prototype enabled the strengths and weaknesses of the software products studied to be identified. When evaluating a software product using the model prototype, it was possible to ascertain its compliance with the standards and use the results to improve it. Since the evaluation was systemic, processes that affect certain characteristics of the product could be identified. Companies can benefit from the model proposed because it serves as a benchmark that allows their products to evolve and be competitive."
"Siakas K.V., Georgiadou E.",Empirical Measurement of the Effects of Cultural Diversity on Software Quality Management,2002,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1842856193&doi=10.1023%2fA%3a1020528024624&partnerID=40&md5=b57d9bcaf695665006cda2cc42988471,"The difficulties of achieving social acceptance for Software Quality Management systems have been underestimated in the past, and they will be exacerbated in the future by the globalization of the software market and the increasing use of cross-cultural development teams within multinational companies. Management that can take account of the cultural context of their endeavours will improve understanding, minimize risk and ensure a higher degree of success in improvement programs within the software industry. This paper addresses cross-cultural issues in Software Quality Management. Qualitative and quantitative research was carried out in five European countries by using a postal questionnaire. Empirical measures of organizational culture, national culture and their interdependence, are presented together with interim instruments developed for the purpose of classifying organizations. Verification of the statistical results from the survey was carried out by triangulation, which included qualitative research methods in the form of interviews and observation. Cultural factors, which may have bearing on successful adoption and implementation of Software Quality Management were identified, and an assessment model, has been developed for use by organizations developing software in different parts of the world. The intention is that the recommendations following from the assessment will lead to greater cultural awareness in addressing quality, and will provide stimulus for improvement. The model's aims is to predict to what degree there is a fit between the organizational and the national culture, and to give recommendations and guidelines for software process improvement."
"Gorton I., Liu A.",Software component quality assessment in practice: Successes and practical impediments,2002,Proceedings-International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036038348&partnerID=40&md5=f02adf14ad9f74556313950b1f9bdd34,"This paper describes the authors' experiences of initiating and sustaining a project at CSIRO aimed at accelerating the successful adoption of COTS middleware technologies in large business and scientific information systems. The projects aims are described, along with example outcomes and an assessment of what is needed for wide-scale software component quality assessments to succeed."
"Parzinger M.J., Nath R., Lemons M.A.",Examining the Effect of the Transformational Leader on Software Quality,2001,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042547833&doi=10.1023%2fA%3a1013763119819&partnerID=40&md5=7d31b7d93f78b6c4d5642bf4db7bae43,"Developing and maintaining quality software is paramount in the information-intensive society. A myriad of concepts, tools and techniques exist that can be employed to improve the quality of software and at the same time increase developmental efficiencies. Approaches used by many software development units include: Capability Maturity Model (CMM), Total Quality Management (TQM), and ISO 9000-3. Implementation of these approaches without appropriate management oversight does not guarantee success. This study examines the role of the manager vis-à-vis ""leadership style"" with software quality. Data collected using a questionnaire administered to members of the American Society for Quality (ASQ) - Software Division, suggest that the Transformational leadership style of the manager has a significant positive relationship with the quality of the software developed."
"Blin M.-J., Tsoukiàs A.",Multi-Criteria Methodology Contribution to the Software Quality Evaluation,2001,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0011893888&doi=10.1023%2fA%3a1016626919680&partnerID=40&md5=a137d99a58bbb4836370b1d4ff3554bc,"Industrial evaluations of COTS software largely used the quality models provided by the international standards. But the context and objectives of COTS evaluations are fundamentally different than those primarily defined by the standards. Several key issues are often forgotten: (1) the existence of several evaluators and several quality models sharing common factors, criteria and measures, (2) the purpose of the evaluation model, (3) measures of different types, and (4) the recursive nature of the model since each node is an evaluation model itself. We had the occasion to study the results of real standard-based COTS evaluations. Faced with the difficulties to exploit them, we experimented the use of multi-criteria methodology. This work allows us to understand some of the problems generated by the application of the standards to COTS evaluations, and to propose new principles for evaluating software quality that should be considered in an evolution of the standards. This paper reports our experiment."
"Balla K., Bemelmans T., Kusters R., Trienekens J.",Quality through Managed Improvement and Measurement (QMIM): Towards a Phased Development and Implementation of a Quality Management System for a Software Company,2001,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010645865&doi=10.1023%2fA%3a1013301503616&partnerID=40&md5=cfe9889727ca12badee4d71ce1c02868,"The paper describes results of a longitudinal study of developments in the area of software product and process quality improvement within a Hungarian software company, IQSOFT Ltd. This company has been active in this area since 1993, trying to build, introduce and maintain an efficiently working quality management system which, e.g., fulfils the ISO 9001 requirements, allows steady software process improvement and, at the same time, conforms to company's own needs. Over the last eight years five phases could be distinguished. Each phase is described shortly, following the same structure, namely: basic starting points, key problem areas, literature consulted, activities and design executed, reflections on what happened and why. The lessons resulting from the analysis of this case have been formulated in terms of guidelines. We feel that these are applicable to any low maturity software development organisation embarking on a product or process quality improvement endeavour. These guidelines are developed around a framework containing the basic issues of software production (project management, technical processes and products). The guidelines advocate a careful step-by-step development of definitions, quality characteristics, and metrics related to these objects while at the same time developing and introducing the associated process."
"Boegh Jorgen, Depanfilis Stefano, Kitchenham Barbara, Pasquini Alberto","Method for software quality planning, control, and evaluation",1999,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033097512&doi=10.1109%2f52.754056&partnerID=40&md5=97fc63f1814469a1306aed28d10729d6,"An increasing number of software process and product standards emphasize the need for measurement. ISO 9001, for example, provides guidance for monitoring and controlling product and process characteristics during both production and installation. However, standards provide little guidance as to what exactly users should measure and how to use the results to support the development of high-quality software. Furthermore, measurement cannot be defined independent of context. A metric set judged valid on one project may lead to poor quality or high development costs when applied to another project. When quality is measured, several factors come into play, including product characteristics (such as size), process maturity level of the company developing the software product, its development environment (such as the design methodology and CASE tools used), and the development team's skill and experience."
"Coleman G., Verbruggen R.",A quality software process for rapid application development,1998,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0542397516&doi=10.1023%2fA%3a1008856624790&partnerID=40&md5=f6924e80eaf9d9671e402727a974b77f,"Software organizations can significantly improve the quality of their output if they have a defined and documented software process, together with the appropriate techniques and tools to measure its effectiveness. Without a defined process it is impossible to measure success or focus on how development capability can be enhanced. To date, a number of software process improvement frameworks have been developed and implemented. However, most of these models have been targeted at large-scale producers. Furthermore, they have applied to companies who use traditional development techniques. Smaller companies and those operating in development areas where speed of delivery is paramount have not, as yet, had process improvement paradigms available for adoption. This study examined the software process in a small company and emerged with the recommendation of the use of the Dynamic Systems Development Method (DSDM) and the Personal Software Process (PSP) for achieving software process improvement."
"Tanaka Takeshi, Aizawa Minoru, Ogasawara Hideto, Yamada Atsushi",Software quality analysis & measurement service activity in the company,1998,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031597187&doi=10.1109%2fICSE.1998.671598&partnerID=40&md5=377b5ac3a4b038bfd392e01d4e7c6600,"It is very important to improve software quality using program analysis & measurement tools and SQA (Software Quality Assurance) method at the appropriate points during the process of development. But in many development departments, there is often not enough time to evaluate and use the tools and SQA method or to accumulate the know-how for effective use. This paper describes the support activity of a software quality analysis & measurement service which is performed by our team of laboratory within the company as a third-party independent staff group. We call this activity HQC (High Quality software creation support virtual Center). The purpose of this activity is as follows. First we improve the software quality engineering process in the development department, for example, we help them to increase efficiency of review or testing. To accomplish this, we use program static analysis tools to detect fault-prone software components. Next we assist in starting their own self-improvement process. In addition, we provide service activity to many development departments concurrently. We have been making progress with these activities, and some development departments have begun to establish improvement process themselves."
"Wilson D.N., Hall T.",Perceptions of software quality : A pilot study,1998,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0011653418&doi=10.1023%2fb%3asqjo.0000042060.88173.fe&partnerID=40&md5=e24784f5ffa40aba778cfd835e019d2a,"Many software quality initiatives fail because they do not take account of the range of views that people have of quality. New approaches to software quality improvement will not work unless software developers believe in them, no matter how enthusiastic managers may be. This paper reports on a pilot study using the repertory grid technique that found evidence to support these assertions. The study findings justify further work and show that while the repertory grid technique is an appropriate instrument in this area it is resource intensive to apply and may not be practical in a wider study of a representative sample of the IT industry. The paper has practical recommendations for successful introduction of new software quality programmes. These recommendations stress the need for effective communication, leading to a shared understanding of 'quality', and for realistic goals that recognize the pressure of development schedules. © 1998 Chapman & Hall."
"Stelzer D., Mellis W., Herzwurm G.",A critical look at ISO 9000 for software quality management,1997,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0642363924&doi=10.1023%2fA%3a1018591430752&partnerID=40&md5=9181348bb75865be23649ef29338594f,"A considerable number of software suppliers report improvements in product and service quality, development costs and time to market achieved with the help of the ISO 9000 standards. Nevertheless, the ISO 9000 family has received unfavourable criticism in journals, textbooks and at software quality conferences. The paper summarizes, discusses and reviews eleven of the most popular arguments against the ISO 9000 standards. The review of the criticism is based on findings of two empirical surveys among European software suppliers that have implemented an ISO 9000 quality system. The paper concludes with suggestions and guidelines for advances in software quality management concepts, such as the ISO 9000 family, CMM, BOOTSTRAP and the emerging SPICE standard."
"Dumke R.R., Grigoleit H.",Efficiency of CAME tools in software quality assurance,1997,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0642333260&doi=10.1023%2fA%3a1018507901618&partnerID=40&md5=0ce0041f30ceaef95ce87fd174655648,"Our paper describes the requirements and possibilities of integration of metrics tools in the field of software quality assurance. Tools for the support of the measurement process are herein classified as Computer Assisted Software Measurement and Evaulation Tools (CAME Tools). Software measurement regarded as a special type of metrics application provides a great amount of basic information for the evaluation of the software development process or the software product itself. Our paper examines the effectiveness and destination of software measurement in tool-based software development and is based on an analysis of more than 20 CAME tools in the Software Measurement Laboratory at the University of Magdeburg. CAME tools are useable for the process, product, and resources evaluation in all phases of the software life cycle (including the problem definition) for different development paradigms. The efficiency of CAME tools is described on the basis of a general measurement framework. This framework includes all steps in the software measurement and evaulation process: metrics definition, selection of the evaluation criteria, tool-based modelling and measurement, value presentation and statistical analysis. The framework includes the main aspects of the process evaluation techniques (Capability Maturity Model, ISO 9000-3 etc.) and product evaluation (ISO 9126, etc.). It is not a disjointed set of aspects: our measurement framework represents an incremental technique for the application of quantification of quality aspects in a required quality assurance."
Van Zeist R.H.J.,Specifying software quality with the extended ISO model,1996,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27144550799&doi=10.1007%2fBF00209185&partnerID=40&md5=64394714677ede47867fcd1a5625efff,"Specifying the quality of software products is a valuable addition to functional specification, clarifying product properties such as learnability and availability. Specifying such properties is considered difficult due to the different parties involved and the implicit nature of the requirements. The QUINT project gathered experience with product specification by means of the Extended ISO model: an extension to the ISO 9126 model of software quality. By defining indicators and specifying how they should be measured, quality specifications can make requirements explicit. Recommendations and pitfalls for composing a specification are grouped by the context in which quality specifications can be used. © 1996 Chapman & Hall."
"Lees B., Jenkins D.G.",Supporting software quality in an integrated safety-critical systems development environment,1996,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27144485773&doi=10.1007%2fBF00419775&partnerID=40&md5=0c3e40005293f7551f4d2a4095e71159,"Research is described, aimed to support traceability in the design of software for safety-critical applications, through the provision of an on-line design journal enabling design decisions and actions to be traced and recorded. The design environment, within which various software design tools may be encapsulated, enables protocol between the user and the design tools to be trapped. This provides software engineering support at the conceptual design stage. An important aim of the research is to enable inferences to be made from the captured protocol, for which the application of artificial intelligence methods is being investigated. © 1996 Chapman & Hall."
Wilson D.N.,Software quality assurance in practice,1996,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0642288948&doi=10.1007%2fBF00419769&partnerID=40&md5=ae4192272b651503278d82f64ef6856e,This paper presents the key findings of a survey of a representative sample of the Australian software industry as to the actual use and application of quality assurance techniques in the development of software. The survey aims to confirm previous survey findings through a management questionnaire and to investigate the software development practices at the 'screen face' through a developer questionnaire. The separate responses are analysed to rate the extent to which quality management practices have penetrated the information systems department. The project commenced in July 1994 and the results of this initial survey support the hypothesis that software quality assurance programmes have not yet penetrated to the systems developers at lower levels of organizations. © 1996 Chapman & Hall.
"Hovenden F.M., Walker S.D., Sharp H.C., Woodman M.",Building quality into scientific software,1996,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038778889&doi=10.1007%2fBF02420942&partnerID=40&md5=bece44920d4927c101c2305f0b37fbe9,"This paper has developed from the SoFEA project at The open University which is studying the non-technical aspects of quality in software. This involves seeing the technical elements of software development as very much part of a wider context. The culture of an organization as a whole, particularly its management strategies, are regarded as driving and shaping the technology. A particular challenge for management we have observed is how to harmonize a skilled individualist (affectionately dubbed a 'maverick') and a quality management system. We explore the characteristics of an individualist programmer and discuss the options for managing such a person. Some of the experiences of a scientific organization are reported. © 1996 Chapman & Hall."
"Kitchenham Barbara, Pfleeger Shari Lawrence",Software quality: the elusive target,1996,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029779819&doi=10.1109%2f52.476281&partnerID=40&md5=0c903484c06cd79cb57e3161badfff3d,"High-profile disasters and the ensuing debates in the press are alerting more people to the crucial nature of software quality in their everyday lives. This should prompt software professionals to take a second look at how they define software quality. In this task of assessing 'adequate' quality in a software product, context is important. Errors tolerated in word-processing software may not be acceptable in control software for a nuclear power plant. Thus, the meanings of 'safety-critical' and 'mission-critical' must be reexamined in the context of software's contribution to the larger functionality and quality of products and businesses. At the same time, software professionals must ask themselves who is responsible for setting quality goals, and make sure they are achieved."
"Khoshgoftaar T.M., Allen E.B., Kalaichelvan K.S., Goel N.",The impact of software evolution and reuse on software quality,1996,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029726553&doi=10.1007%2fBF00125810&partnerID=40&md5=22f6cf0451a62716aa68a29a14e0ca89,"This paper presents a case study of a software project in the maintenance phase. The case study was based on a sample of modules, representing about 1.3 million lines of code, from a very large telecommunications system. Software quality models were developed to predict the number of faults expected from the coding through operations phases. Since modules from the prior release were often reused to develop a new release, one model incorporated reuse data as additional independent variables. We compare this model's performance to a similar model without reuse data. Software quality models often have product metrics as the only input data for predicting quality. There is an implicit assumption that all the modules have had a similar development history, so that product attributes are the primary drivers of different quality levels. Reuse of software as components and software evolution do not fit this assumption very well, and consequently, traditional models for such environments may not have adequate accuracy. Focusing on the software maintenance phase, this study demonstrated that reuse data can significantly improve the predictive accuracy of software quality models. © 1996 Kluwer Academic Publishers."
"Saiedian H., Mcclanahan L.M.",Frameworks for quality software process: SEI Capability maturity model versus ISO 9000,1996,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0007663827&doi=10.1007%2fBF02420941&partnerID=40&md5=920d8525d6033e615724b4a8ab7ec770,"With the historical characterization of software development as being costly due to massive schedule delays, incorporation of the ever-changing technology, budget reductions, and missing customer requirements, the trend of the 1990s in establishing a quality improvement or a quality assurance programme has been overwhelming. The two popular models or frameworks for assessment of a quality assurance programme are the US government-sponsored Capability Maturity Model (CMM) and the internationally recognized ISO-9000 quality standards. Both of these two frameworks share a common concern regarding software quality and process management. Since it is not clear which of these two frameworks is most effective in achieving their shared objectives, it is valuable and timely to provide an objective overview of both models and to compare and contrast their features for quality software development. Because there are many legitimate areas for comparison, we have selected the two most important as a basis for comparison: (1) the role of management, and (2) the application of measurements. We also provide a summary of the reported impact of these two models on the organizations adhering to their standards, and include our observations and analysis. © 1996 Chapman & Hall."
Mcguire E.G.,Factors affecting the quality of software project management:an empirical study based on the Capability Maturity Model,1996,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0007176737&doi=10.1007%2fBF00209188&partnerID=40&md5=8a9f2fa4e39735762608ce94c38112e4,"Rigorous project management can help raise a software product development process from an initial, immature stage that is unstable and unrepeatable to an optimized maturity level characterized by continuous improvement and innovation. Goals and actions related to a repeatable project management process have been outlined in the Capability Maturity Model (CMM) developed by the Software Engineering Institute at Carnegie Mellon University. The CMM provides good guidelines for initiating software process improvement particularly in the project management area; however, the successful implementation of the CMM guidelines is often not accomplished without significant organizational change involving increased emphasis on change management, teams and employee empowerment. This paper is empirically based on observations, surveys, and interviews of project team managers and project team members in a large, multinational organization. The focus of the paper is on the development of a project management process that emphasizes project planning, change management, quality management, team work, and process control. Findings presented in this paper are correlated with the CMM guidelines as well as organizational factors that were found to enable or impede the successful deployment of various aspects of a project management improvement plan. The role of education and training in process and quality techniques as well as project management tools that support group work is also examined. This paper provides some insight into the issues faced by organizations based on traditional hierarchy or matrix management as they attempt to move into a more process-driven, quality-oriented development environment. As organizations move towards global markets they need increased emphasis on quality, value, teams, standards and global project management strategies based on structured guidelines to handle process Sow within and between projects, departments, organizations, and national boundaries. © 1996 Chapman & Hall."
"Ogasawara Hideto, Yamada Atsushi, Kojo Michiko",Experiences of software quality management using metrics through the life-cycle,1995,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029516009&partnerID=40&md5=68106def0b53f2f1a609753364cb4705,"Many software quality metrics to objectively grasp software products and process have been proposed in the past decades. In actual projects, quality metrics has been widely applied to manage software quality. However, there are still several problems with providing effective feedback to intermediate software products and the software development process. We have proposed a software quality management using quality metrics which are easily and automatically measured. The purpose of this proposal is to establish a method for building in software quality by regularly measuring and reviewing. This paper outlines a model for building in software quality using quality metrics, and describes examples of its application to actual projects and its results. As the results, it was found that quality metrics can be used to detect and remove problems with process and products in each phase. Regular technical reviews using quality metrics and information on the change of the regularly measured results was also found to have a positive influence on the structure and module size of programs. Further, in the test phase, it was found that with the proposed model, the progress of corrective action could be quickly and accurately grasped."
Schneidewind N.F.,Controlling and predicting the quality of space shuttle software using metrics,1995,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0343935307&doi=10.1007%2fBF00404649&partnerID=40&md5=b99281a03e36e4acaf4ca5067792314f,"Software quality metrics have potential for helping to assure the quality of software on large projects such as the Space Shuttle flight software. It is feasible to validate metrics for controlling and predicting software quality during design by validating metrics against a quality factor. Quality factors, like reliability, are of more interest to customers than metrics, like complexity. However quality factors cannot be collected until late in a project. Therefore the need arises to validate metrics, which developers can collect early in a project, against a quality factor. We investigate the feasibility of validating metrics for controlling and predicting quality on the Space Shuttle. The key to the approach is the use of validated metrics for early identification and resolution of quality problems. © 1995 Chapman & Hall."
"Khoshgoftaar T.M., Szabo R.M.",Investigating ARIMA models of software system quality,1995,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041854073&doi=10.1007%2fBF00404648&partnerID=40&md5=15c3a41784f9123e8bb6ab0610493edd,"In this paper, we investigate how to incorporate program complexity measures with a software quality model. We collect software complexity metrics and fault counts from each build during the testing phase of a large commercial software system. Though the data are limited in quantity, we are able to predict the number of faults in the next build. The technique we used is called times series analysis and forecasting. The methodology assumes that future predictions are based on the history of past observations. We will show that the combined complexity quality model is an improvement over the simpler quality only model. Finally, we explore how the testing process used in this development may be improved by using these predictions and suggest areas for future research. © 1995 Chapman & Hall."
"Griss M.L., Wosser M., Lawrence S.",Making reuse work at hewlett-packard: New views of mature ideas on software quality and productivity,1995,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029209751&doi=10.1109%2f52.363160&partnerID=40&md5=3d249047685628a9cb304239925e7bdd,"For the last seven years, Martin Griss and his colleagues have investigated how Hewlett-Packard can improve its software-development process using systematic software reuse. Griss has been a professor, research laboratory manager, and industrial researcher. Marty Wosser has worked closely with him on software reuse for four years. In this column, they share some of what HP has learned about software ware reuse. This column, which builds on a talk Griss delivered at the International Conference on Software Engineering last May, can help you manage expectations about what software reuse can and cannot deliver. - Shari Lawrence Pfleeger. © 1995, IEEE. All rights reserved."
Neil M.,Measurement as an alternative to bureaucracy for the achievement of software quality,1994,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542478267&doi=10.1007%2fBF00213631&partnerID=40&md5=d7492a6bd3774989e38bb87ab5119d87,"In this paper we discuss the two dominant modes of thought on the problem of software quality: the bureaucratic approach and the technical approach. The aim of the paper is to pursue the issues of how these approaches affect people, in our case software developers, and how we can assess the effectiveness of each approach in actually achieving quality software. An outline of the main aspects of the organizational approach - process modelling and software standards - is given. In order to address the effects of each of these modes of thought on people we take a psychological perspective. The implications for software engineering, in terms of formalism and mechanization, are discussed. The paper argues that overzealous structure, control and automation can negatively affect the creative process of developing software. A perspective on each of the components of the technical approach in terms of their effectiveness in achieving quality objectives is provided. From recent work we find that process modelling and many software standards do not provide an adequate assessment of the benefits derived from their application. The paper argues that measurement goes some way to addressing these problems. Measurement should form the core of the software development process, especially with respect to product quality assessment. The main conclusion is that by focusing on measurable objectives and results we can best achieve quality software products and highlight the processes which are likely to create them in a repeatable and manageable fashion. Additionally, by adopting measurement in practice we should expect to increase the freedom and creativity of software developers. © 1994 Chapman & Hall."
"Avison D.E., Shah H.U., Wilson D.N.",Software quality standards in practice: the limitations of using ISO-9001 to support software development,1994,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0642350288&doi=10.1007%2fBF00213633&partnerID=40&md5=be0ebcd16c03c9f6fa5176748491b323,Quality management standard BS5740/ISO9001 is a key technology for UK and Europe in the 1990s. This paper shows that the relevance of BS5750/ISO9001 is limited and suggests that standards bodies must develop and endorse new standards to ensure that software quality improvement programmes continue to be adopted by the information technology industry. © 1994 Chapman & Hall.
Johnson Philip M.,Instrumented approach to improving software quality through formal technical review,1994,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028166449&partnerID=40&md5=c55ee6fec781782a4eb7db9c7fa9cf69,"Formal technical review (FTR) is an essential component of all software quality assessment, assurance, and improvement techniques. However, current FTR practice leads to significant expense, clerical overhead, group process obstacles, and research methodology problems. CSRS is an instrumented, computer-supported cooperative work environment for formal technical review. CSRS addresses problems in the practice of FTR by providing computer support for both the process and products of FTR. CSRS also addresses problems in research on FTR through instrumentation supporting fine-grained, high quality data collection and analysis. This paper describes CSRS, a computer-mediated review method called FTArm, and selected findings from their use to explore issues in formal technical review."
"Davis C.J., Gillies A.C., Smith P., Thompson J.B.",Current practice in software quality and the impact of certification schemes,1993,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2842588521&doi=10.1007%2fBF00402266&partnerID=40&md5=f1cdb90f397e6b6b9f4998e9dd9393fd,"The paper presents the findings of a survey that investigated the level of quality management practice within some 150 UK companies from a sample of 500. It provides a snapshot of practice at the time of the survey, and assesses the impact of government quality initiatives particularly, the TickIT scheme at that time. The survey methodology is described, together with the results and conclusions. The sample has been graded by size of company, which the authors consider to have a significant effect upon the adoption of quality practices. The survey highlights the need to encourage small companies to adopt quality practices and to assist them with the short-term costs incurred. © 1993 Chapman & Hall."
"Benford S., Burke E., Foxley E.",Learning to construct quality software with the Ceilidh system,1993,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040852870&doi=10.1007%2fBF00402268&partnerID=40&md5=127168499618aa23dab70cfc64d01be1,"This paper describes the Ceilidh software quality control environment for the teaching of computer programming. Ceilidh provides students with an integrated environment for developing programs according to specifications and quality standards defined by the teacher. The student's programs are automatically assessed from a number of perspectives including dynamic correctness, program complexity and programming style. The assessment of programs is carried out according to well established software metrics and students may repeatedly re-assess their programs, enabling them gradually to work towards a quality target. The paper gives an overview of the functionality of Ceilidh followed by a more detailed description of the software metrics used. It also discusses some of the insights gained from several years' use at Nottingham. Finally, the paper outlines plans for the future development of Ceilidh including a pilot project involving 30 UK institutes of higher education funded under the Universities Funding Council's Teaching and Learning Technology Programme (TLTP). The paper should be of particular interest to anyone involved in teaching programming, whether it be in university, in schools or in industry, who might wish to construct a similar system or who might wish to obtain and use Ceilidh directly. It should also be of interest to those looking for experiences gained from large-scale applications of software quality metrics. © 1993 Chapman & Hall."
"Gordon V.S., Bieman J.M.",Reported effects of rapid prototyping on industrial software quality,1993,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542792758&doi=10.1007%2fBF00590438&partnerID=40&md5=009b39f0d0b8ac296cefe8827777683c,"Empirical data are required to determine the effect of rapid prototyping on software quality. We examine 34 published and unpublished case studies of the use of rapid prototyping in 'real-world' software development. We identify common observations, unique events, and opinions. We develop guidelines to help software developers use rapid prototyping to maximize product quality and avoid common pitfalls. © 1993 Chapman & Hall."
"Dalal S.R., Horgan J.R., Kettenring J.R.","Reliable software and communication: software quality, reliability, and safety",1993,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027208332&doi=10.1109%2fICSE.1993.346023&partnerID=40&md5=7ffb40c895d81738e0e5f41e5e1e5fed,"The software created by industrial, educational, and research organizations is increasingly large and complex. It also occupies a central role in the reliability and safety of many essential services. We examine the software development process and suggest opportunities for improving the process by using a combination of statistical and other process control techniques. Data, analysis of data, and tools for collecting data are crucial to our approach. Though our views are based upon experiences with large telecommunications systems, they are likely to be useful to many other developers of large software systems."
Rubin Howard A.,Software process maturity: measuring its impact on productivity and quality,1993,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027150237&doi=10.1109%2fICSE.1993.346019&partnerID=40&md5=8d9c01a05ed505732258e69067392a1f,"With the current worldwide focus on improvement in software process, there is clearly a need for an understanding of its impact on software engineering productivity and quality. This paper documents an attempt to provide an empirical metrics ″view″ of such initiatives based on data collected in a worldwide benchmarking effort conducted between March, 1991 and December, 1991. Surprisingly, of the more than 300 organizations that participated, fewer than 1 in 5 had any quantifiable performance data available prior to the start of this study. However, those that had embarked on significant process improvement efforts and were actively using metrics were able to demonstrate substantial gains in productivity and quality. In addition, insights derived from this large scale data analysis provide a framework for determining which metrics should be included in a standard software engineering measurement 'dashboard'."
Gillies A.,Modelling software quality in the commercial environment,1992,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001332319&doi=10.1007%2fBF01720924&partnerID=40&md5=a0b468b060b629ea3ced5fefac2c2848,"Achieving quality is a perennial problem in software development. It is commercially significant because of the large sums of money spent correcting problems within information systems. The literature shows how various theoretical treatments have developed since the late 1970s. However, many of these models are of academic interest only, because they are not perceived by IT professionals to meet their needs. This article describes a study which examined the nature of quality in six different commercial environments. The aim of the study was to provide models of quality appropriate to individual commercial environments and to examine similarities between them. The results, expressed in terms of quality criteria and the relationships between them, highlight the limitations of many theoretical treatments, in particular, the highly technical view of software quality enshrined in early models, and the need for criteria contributing to 'business correctness'. The results from the study are used to highlight some of the important issues in software quality within commercial environments and some of the reasons why quality is often poor. © 1992 Chapman & Hall."
"Dromey R.G., McGettrick A.D.",On specifying software quality,1992,Software Quality Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0008302517&doi=10.1007%2fBF01720169&partnerID=40&md5=f297222c53ba1b94f0ae36ebdd761820,"Quality is recognized as a pre-eminently important characteristic of software, yet an understanding of how to usefully define it, and how to achieve it remains illusive. A constructive definition of quality is investigated and an approach to the construction of software of quality is suggested. The definition focusses on how well the solution fits the problem, the inherent quality of the design independent of the problem, and the quality of the design process that creates the solution. A constructive specification of software quality then follows based on the use of programming language syntax, design principles and strategies, post-construction program quality analysis systems, and computer-assisted program construction tools. Only by addressing the problem on much broader methodological, technical, and managerial fronts will it be possible to make significant gains in software quality. © 1992 Chapman & Hall."
"Ehrlich Willa K., Stampfel John P., Wu Jar R.",Application of software reliability modeling to product quality and test process,1990,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025135323&partnerID=40&md5=b4dbdc121b20e110987e3f1af36ed7e5,"Software reliability modeling of data collected during the testing of a large-scale industrial system (System T) was used to measure software quality from the customer perspective. Specifically, software quality was measured in terms of the system operation. The testing phase analyzed, stability test, was an operational profile-driven test in that a controlled load was imposed on the system reflective of the system's busy-hour usage pattern. The usage profile was determined from requirements specifying both the frequency of invocation of each command and the alarm arrival rate for the largest expected user site. For this controlled test environment, a Poisson-type reliability growth model, the exponential nonhomogeneous Poisson process model, exhibited a good fit to the observed failure data. Furthermore, the model demonstrated predictive power for future failure rates. It is concluded that the use of an operational profile to drive system test is an effective test strategy and that the operational profile must be taken into account when predicting field reliability from reliability measured during test."
Bush Marilyn,Improving software quality: The use of formal inspections at the Jet Propulsion Laboratory,1990,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025065689&partnerID=40&md5=076b67661eb8df873ac5134e5a499fea,"After surveying detection practices in the best of industry, JPL (Jet Propulstion Laboratory) Software Product Assurance decided that the most cost-effective early defect detection technique was the 'Fagan Inspection' procedure. The author describes this technique, how it was introduced to JPL, some of the difficulties involved in 'transferring technology,' and the first provisional set of results."
"Hirayama Masayuki, Sato Hiroyuki, Yamada Atushi, Tsuda Junichiro",Practice of quality modeling and measurement on software life-cycle,1990,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025022794&partnerID=40&md5=155e3e9926c8e675616e8d839798a6e1,"The authors introduce quality metrics into the quantitative software quality estimation technique, embracing the quality estimate of design, as well as of the source code, in studying a quality quantification support system. They outline a quality quantification technique for this system, describe examples of both its application to actual projects and its evaluation, and consider its relationship conventional techniques for estimate indexing of T. J. McCabe (IEEE Trans. Softw. Eng., vol. SE-2, no. 4, 1976) and M. H. Halstead (Elements of Software Science, North Holland, NY, 1977)."
"Collofello J.S., Buck J.J.",Software Quality Assurance for Maintenance,1987,IEEE Software,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042984162&doi=10.1109%2fMS.1987.231418&partnerID=40&md5=c58510c37ada8347e2c7b69b25c6c346,"Maintenance plays a vital role in protecting quality as a system evolves. The results of this study pinpoint how to make maintenance a SQA. Copyright © 1987 by The Institute of Electrical and Electronics Engineers, Inc."
"Boehm B.W., Brown J.R., Lipow M.",Quantitative evaluation of software quality,1976,Proceedings - International Conference on Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042377749&partnerID=40&md5=86df793c94725cf352a0b8b3d8227c3c,"The study reported in this paper establishes a conceptual framework and some key initial results in the analysis of the characteristics of software quality. Its main results and conclusions are: • Explicit attention to characteristics of software quality can lead to significant savings in software life-cycle costs. • The current software state-of-the-art imposes specific limitations on our ability to automatically and quantitatively evaluate the quality of software. • A definitive hierarchy of well-defined, well-differentiated characteristics of software quality is developed. Its higher-level structure reflects the actual uses to which software quality evaluation would be put; its lower-level characteristics are closely correlated with actual software metric evaluations which can be performed. • A large number of software quality-evaluation metrics have been defined, classified, and evaluated with respect to their potential benefits, quantifiability, and ease of automation. • Particular software life-cycle activities have been identified which have significant leverage on software quality. Most importantly, we believe that the study reported in this paper provides for the first time a clear, well-defined framework for assessing the often slippery issues associated with software quality, via the consistent and mutually supportive sets of definitions, distinctions, guidelines, and experiences cited. This framework is certainly not complete, but it has been brought to a point sufficient to serve as a viable basis for future refinements and extensions. © 1976 IEEE Computer Society. All rights reserved."
